{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fEGztEl3U2P5"
   },
   "source": [
    "## [Lucille Kaleha ](https://www.linkedin.com/in/lucillekaleha/): **Second position solution for the Womxn in Big Data South Africa competition**\n",
    "\n",
    "\n",
    "---\n",
    "*Thanks to Zindi, Women in Big Data, HERE Technologies and Microsoft for this challenge and opportunity to improve livelihoods using Data Science*\n",
    "\n",
    "### Challenges faced:\n",
    " - Feature engineering did not yield good results\n",
    " - There was no correlation between local cross validation and the leaderbaord, so it was challenging to know how good a model is and whether it was overfitting\n",
    " - Using all the data for training yielded worse results\n",
    " - It was very challenging to get new data from the recommended HERE and XYZ apis.\n",
    " \n",
    "### Approach used:\n",
    " - Focused more on bulding models rather than feature engineering\n",
    " - As location was an important feature, i reverse geocoded the coordinates to get locations for each latitude and longitude using the reversegeocoding python library\n",
    " - As there was no single model that yielded good results, i opted to train several models so that they can cancel each others errors and generalize well\n",
    " - Because using all the data yielded unsatisfactory resultes, i opted to train each model with 70% of the data\n",
    " - To ensure that all the data has been used for training, i used different random states to split the data\n",
    " - Finally to generalise the ensembled models; I averaged, blended and retrained the models using the test data as training data and predictions as the target\n",
    " \n",
    "### Some small caveats:\n",
    " - I realised that using different versions of catboost regressor yielded different results, so i maximised on this and used two versions of catboost.\n",
    "    - At some point in the notebook you will have to restart the kernel.\n",
    " - Setting the random states(seed) did help for reproducability, but some models dont have the random state parameter, so there is some bias/randomness that cannot be accounted for. So predictions will differ by a small margin whenever you run the notebook.\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "colab_type": "code",
    "id": "WqAO45Wq7Y_g",
    "outputId": "b6679347-76e2-45b6-acd9-7b096c26414f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vecstack in /home/philmassie/snap/jupyter/common/lib/python3.7/site-packages (0.4.0)\n",
      "Requirement already satisfied: numpy in /home/philmassie/snap/jupyter/common/lib/python3.7/site-packages (from vecstack) (1.17.4)\n",
      "Requirement already satisfied: scipy in /home/philmassie/snap/jupyter/common/lib/python3.7/site-packages (from vecstack) (1.3.3)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /home/philmassie/snap/jupyter/common/lib/python3.7/site-packages (from vecstack) (0.22)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/philmassie/snap/jupyter/common/lib/python3.7/site-packages (from scikit-learn>=0.18->vecstack) (0.14.0)\n",
      "Requirement already satisfied: catboost==0.20.2 in /home/philmassie/snap/jupyter/common/lib/python3.7/site-packages (0.20.2)\n",
      "Requirement already satisfied: six in /snap/jupyter/6/lib/python3.7/site-packages (from catboost==0.20.2) (1.12.0)\n",
      "Requirement already satisfied: matplotlib in /home/philmassie/snap/jupyter/common/lib/python3.7/site-packages (from catboost==0.20.2) (3.1.2)\n",
      "Requirement already satisfied: plotly in /home/philmassie/snap/jupyter/common/lib/python3.7/site-packages (from catboost==0.20.2) (4.4.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /home/philmassie/snap/jupyter/common/lib/python3.7/site-packages (from catboost==0.20.2) (1.17.4)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /home/philmassie/snap/jupyter/common/lib/python3.7/site-packages (from catboost==0.20.2) (0.25.3)\n",
      "Requirement already satisfied: scipy in /home/philmassie/snap/jupyter/common/lib/python3.7/site-packages (from catboost==0.20.2) (1.3.3)\n",
      "Requirement already satisfied: graphviz in /home/philmassie/snap/jupyter/common/lib/python3.7/site-packages (from catboost==0.20.2) (0.13.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/philmassie/snap/jupyter/common/lib/python3.7/site-packages (from matplotlib->catboost==0.20.2) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /snap/jupyter/6/lib/python3.7/site-packages (from matplotlib->catboost==0.20.2) (2.8.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/philmassie/snap/jupyter/common/lib/python3.7/site-packages (from matplotlib->catboost==0.20.2) (2.4.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/philmassie/snap/jupyter/common/lib/python3.7/site-packages (from matplotlib->catboost==0.20.2) (0.10.0)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /home/philmassie/snap/jupyter/common/lib/python3.7/site-packages (from plotly->catboost==0.20.2) (1.3.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/philmassie/snap/jupyter/common/lib/python3.7/site-packages (from pandas>=0.24.0->catboost==0.20.2) (2019.3)\n",
      "Requirement already satisfied: setuptools in /snap/jupyter/6/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->catboost==0.20.2) (41.0.1)\n",
      "Requirement already satisfied: reverse_geocoder in /home/philmassie/snap/jupyter/common/lib/python3.7/site-packages (1.5.1)\n",
      "Requirement already satisfied: scipy>=0.17.1 in /home/philmassie/snap/jupyter/common/lib/python3.7/site-packages (from reverse_geocoder) (1.3.3)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /home/philmassie/snap/jupyter/common/lib/python3.7/site-packages (from reverse_geocoder) (1.17.4)\n"
     ]
    }
   ],
   "source": [
    "# Installing the necessary libraries\n",
    "#\n",
    "!pip install vecstack                   # For stacking models\n",
    "!pip install catboost==0.20.2           # This version of catboost yielded better results with certain random states\n",
    "!pip install reverse_geocoder           # Used to get location of a place, given coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "67UJh-5jkRL6"
   },
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import StringIO \n",
    "import reverse_geocoder as rg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR, NuSVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor, XGBRFRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, BayesianRidge\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor,HistGradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from lightgbm import LGBMRegressor\n",
    "from vecstack import stacking\n",
    "from vecstack import StackingTransformer\n",
    "from catboost import CatBoostRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QOSZr0a113UC"
   },
   "source": [
    "### Loading and cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wRMvzJcBfUKJ"
   },
   "outputs": [],
   "source": [
    "# Created links to shared files via google drive\n",
    "#\n",
    "train = pd.read_csv(\"Train.csv\")\n",
    "test = pd.read_csv(\"Test.csv\")\n",
    "submission = pd.read_csv(\"SampleSubmission.csv\")\n",
    "dictionary = pd.read_csv(\"variable_descriptions.csv\")\n",
    "\n",
    "# Created a function to read a csv file shared via google and return a dataframe\n",
    "#\n",
    "def read_csv(url):\n",
    "  url = 'https://drive.google.com/uc?export=download&id=' + url.split('/')[-2]\n",
    "  csv_raw = requests.get(url).text\n",
    "  csv = StringIO(csv_raw)\n",
    "  df = pd.read_csv(csv)\n",
    "  return df\n",
    "\n",
    "# Creating submission, training, testing and variable definition datataframes\n",
    "#\n",
    "#sub = read_csv(submission)\n",
    "#train = read_csv(train)\n",
    "#test = read_csv(test)\n",
    "#submission = read_csv(submission)\n",
    "#dictionary = read_csv(dictionary)\n",
    "\n",
    "# Splitting the target variable from the train dataframe\n",
    "#\n",
    "target = train.target\n",
    "\n",
    "\n",
    "# Aligning the training and testing datasets\n",
    "train, test = train.align(test, join = 'inner', axis = 1)\n",
    "\n",
    "\n",
    "# Including a separator column to be used to split the dataframes after combining them\n",
    "#\n",
    "train['separator'] = 0\n",
    "test['separator'] = 1\n",
    "\n",
    "\n",
    "# Combining the test and train dataframes, so that feature engineering can be done on the go\n",
    "#\n",
    "comb = pd.concat([train, test])\n",
    "\n",
    "# Separating the training and testing dataframes from the combined dataframe\n",
    "#\n",
    "train = comb[comb.separator == 0]\n",
    "test = comb[comb.separator == 1]\n",
    "\n",
    "\n",
    "# Dropping the separator column as it has served its purpose\n",
    "#\n",
    "train.drop('separator', axis = 1, inplace = True)\n",
    "test.drop('separator', axis = 1, inplace = True)\n",
    "train['target'] = target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BQFw7hoL18qU"
   },
   "source": [
    "### Catboost Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q-QpiT7rlX49"
   },
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing dataframes\n",
    "#\n",
    "X = train.drop(['ward', 'ADM4_PCODE', 'target'], axis = 1)  # Predictors\n",
    "y = target                                                  # Target\n",
    "\n",
    "tes = test.drop(['ward', 'ADM4_PCODE'], axis = 1)           # Testing data\n",
    "\n",
    "# Splitting the training dataset to 70%, and setting the random state to 90\n",
    "#\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 90)\n",
    "\n",
    "# Making predictions\n",
    "#\n",
    "predictions_cat = CatBoostRegressor(logging_level='Silent').fit(X_train, y_train).predict(tes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ph8CUGE92Kmp"
   },
   "source": [
    "### Sklearn Stacking Regressor Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J9aXdPYEe-YK"
   },
   "outputs": [],
   "source": [
    "# Using two different stacked ensembles to make predictions using the sklearn stacking regressor\n",
    "#\n",
    "X = train.drop(['ward', 'ADM4_PCODE', 'target'], axis = 1)\n",
    "y = target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 90)\n",
    "\n",
    "tes = test.drop(['ward', 'ADM4_PCODE'], axis = 1)\n",
    "\n",
    "estimators_1 = [\n",
    "    ('xgb', XGBRegressor(objective ='reg:squarederror')),\n",
    "    ('lr', LinearRegression()),\n",
    "    ('rf', RandomForestRegressor()),\n",
    "    ('lgb', LGBMRegressor()),\n",
    "    ('svr', SVR()),\n",
    "    ('lasso', Lasso()),\n",
    "    ('kneiba', KNeighborsRegressor()),\n",
    "    ('cat', CatBoostRegressor(logging_level='Silent'))\n",
    "]\n",
    "\n",
    "predictions_sreg = StackingRegressor(estimators=estimators_1, final_estimator=CatBoostRegressor(logging_level='Silent')).fit(X_train, y_train).predict(tes)\n",
    "\n",
    "\n",
    "estimators_2 = [\n",
    "    ('XBRF', XGBRFRegressor(objective ='reg:squarederror')),\n",
    "    ('Bayesian', BayesianRidge()),\n",
    "    ('ExtraTrees', ExtraTreesRegressor()),\n",
    "    ('HistGradient', HistGradientBoostingRegressor()),\n",
    "    ('NuSVR', NuSVR()),\n",
    "    ('Ridge', Ridge()),\n",
    "    ('KNeiba', KNeighborsRegressor()),\n",
    "    ('cat', CatBoostRegressor(logging_level='Silent'))\n",
    "]\n",
    "\n",
    "predictions_sreg_2 = StackingRegressor(estimators=estimators_2, final_estimator=CatBoostRegressor(logging_level='Silent')).fit(X_train, y_train).predict(tes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aUYyZQn82PZF"
   },
   "source": [
    "### Vecstack Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L74m8Rx1e-VN"
   },
   "outputs": [],
   "source": [
    "# Using two different stacked ensembles to make predictions using the vecstack stacking regressor\n",
    "#\n",
    "X = train.drop(['ward', 'ADM4_PCODE', 'target'], axis = 1)\n",
    "y = target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 90)\n",
    "\n",
    "tes = test.drop(['ward', 'ADM4_PCODE'], axis = 1)\n",
    "\n",
    "estimators_1 = [\n",
    "    ('xgb', XGBRegressor(objective ='reg:squarederror')),\n",
    "    ('lr', LinearRegression()),\n",
    "    ('rf', RandomForestRegressor()),\n",
    "    ('lgb', LGBMRegressor()),\n",
    "    ('svr', SVR()),\n",
    "    ('lasso', Lasso()),\n",
    "    ('kneiba', KNeighborsRegressor()),\n",
    "    ('cat', CatBoostRegressor(logging_level='Silent'))\n",
    "]\n",
    "\n",
    "stack = StackingTransformer(estimators_1, regression=True, verbose=0, metric =mean_squared_error, shuffle=True)\n",
    "stack = stack.fit(X_train, y_train)\n",
    "S_train = stack.transform(X_train)\n",
    "\n",
    "\n",
    "final_estimator = CatBoostRegressor(logging_level='Silent')\n",
    "final_estimator = final_estimator.fit(S_train, y_train)\n",
    "\n",
    "S_tes = stack.transform(tes)\n",
    "predictions_vecstack = final_estimator.predict(S_tes)\n",
    "\n",
    "\n",
    "\n",
    "estimators_2 = [\n",
    "    ('XBRF', XGBRFRegressor(objective ='reg:squarederror')),\n",
    "    ('Bayesian', BayesianRidge()),\n",
    "    ('ExtraTrees', ExtraTreesRegressor()),\n",
    "    ('HistGradient', HistGradientBoostingRegressor()),\n",
    "    ('NuSVR', NuSVR()),\n",
    "    ('Ridge', Ridge()),\n",
    "    ('KNeiba', KNeighborsRegressor()),\n",
    "    ('cat', CatBoostRegressor(logging_level='Silent'))\n",
    "]\n",
    "\n",
    "stack = StackingTransformer(estimators_2, regression=True, verbose=0, metric =mean_squared_error, shuffle=True)\n",
    "stack = stack.fit(X_train, y_train)\n",
    "S_train = stack.transform(X_train)\n",
    "\n",
    "\n",
    "final_estimator = CatBoostRegressor(logging_level='Silent')\n",
    "final_estimator = final_estimator.fit(S_train, y_train)\n",
    "\n",
    "S_tes = stack.transform(tes)\n",
    "predictions_vecstack_2 = final_estimator.predict(S_tes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Est6Jhsi6Oa"
   },
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tNKqShSb_agx"
   },
   "outputs": [],
   "source": [
    "# Created links to shared files via google drive\n",
    "#\n",
    "train = pd.read_csv(\"Train.csv\")\n",
    "test = pd.read_csv(\"Test.csv\")\n",
    "submission = pd.read_csv(\"SampleSubmission.csv\")\n",
    "dictionary = pd.read_csv(\"variable_descriptions.csv\")\n",
    "\n",
    "\n",
    "# Created a function to read a csv file shared via google and return a dataframe\n",
    "#\n",
    "def read_csv(url):\n",
    "  url = 'https://drive.google.com/uc?export=download&id=' + url.split('/')[-2]\n",
    "  csv_raw = requests.get(url).text\n",
    "  csv = StringIO(csv_raw)\n",
    "  df = pd.read_csv(csv)\n",
    "  return df\n",
    "\n",
    "# Creating submission, training, testing and variable definition datataframes\n",
    "#\n",
    "#sub = read_csv(submission)\n",
    "#train = read_csv(train)\n",
    "#test = read_csv(test)\n",
    "#submission = read_csv(submission)\n",
    "#dictionary = read_csv(dictionary)\n",
    "\n",
    "# Splitting the target variable from the train dataframe\n",
    "#\n",
    "target = train.target\n",
    "\n",
    "\n",
    "# Aligning the training and testing datasets\n",
    "train, test = train.align(test, join = 'inner', axis = 1)\n",
    "\n",
    "\n",
    "# Including a separator column to be used to split the dataframes after combining them\n",
    "#\n",
    "train['separator'] = 0\n",
    "test['separator'] = 1\n",
    "\n",
    "\n",
    "# Combining the test and train dataframes, so that feature engineering can be done on the go\n",
    "#\n",
    "comb = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-WHQcFpI_aWc"
   },
   "outputs": [],
   "source": [
    "# # Reverse geocoding coordinates to locations\n",
    "# #\n",
    "# name = []\n",
    "\n",
    "# for i in range(len(comb)):\n",
    "#   location = rg.search([(x, y) for x, y in zip(comb.lat, comb.lon)][i])\n",
    "#   name.append(location[0].get('name'))\n",
    "\n",
    "\n",
    "# # Adding the geocoded locations to the combined dataframe\n",
    "# comb['name'] = name\n",
    "\n",
    "# # Creating a csv file of the combined dataframe\n",
    "# comb.to_csv('women_comb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "26jJrCIJhd0w"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'women_comb.csv' does not exist: b'women_comb.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c466fe76985d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Loading the combined created csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcomb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'women_comb.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philmassie/snap/jupyter/common/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philmassie/snap/jupyter/common/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philmassie/snap/jupyter/common/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philmassie/snap/jupyter/common/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philmassie/snap/jupyter/common/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'women_comb.csv' does not exist: b'women_comb.csv'"
     ]
    }
   ],
   "source": [
    "# Loading the combined created csv\n",
    "#\n",
    "comb = pd.read_csv('women_comb.csv', index_col = 0)\n",
    "\n",
    "\n",
    "# Creating a column of how many time a location is represented in the dataset\n",
    "#\n",
    "freq_cols = ['name']\n",
    "for col in freq_cols:\n",
    "  fq_encode = comb[col].value_counts().to_dict()\n",
    "  comb[col+'_fq_enc'] = comb[col].map(fq_encode)\n",
    "\n",
    "# One hot encoding the location column\n",
    "#\n",
    "comb = pd.get_dummies(comb, columns = ['name'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AFvrcOJRo024"
   },
   "outputs": [],
   "source": [
    "# Generating more features\n",
    "#\n",
    "comb['Household_Size'] = comb['total_individuals']/comb['total_households']\n",
    "comb['psa_car1_car_2'] = comb.psa_00/(comb.car_00 + comb.car_01)\n",
    "comb['latlon'] = abs(comb.lat) + abs(comb.lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZwUa1wWbktmd"
   },
   "outputs": [],
   "source": [
    "# Separating the train and test dataframes from the combined dataframe\n",
    "#\n",
    "train = comb[comb.separator == 0]\n",
    "test = comb[comb.separator == 1]\n",
    "\n",
    "train.drop('separator', axis = 1, inplace = True)\n",
    "test.drop('separator', axis = 1, inplace = True)\n",
    "train['target'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5eee1e4hktft"
   },
   "outputs": [],
   "source": [
    "# Training the data with the new features and making predictions\n",
    "#\n",
    "X = train.drop(['ward', 'ADM4_PCODE', 'target'], axis = 1)\n",
    "y = target\n",
    "tes = test.drop(['ward', 'ADM4_PCODE'], axis = 1)\n",
    "\n",
    "predictions_feats = CatBoostRegressor(logging_level='Silent', random_state=101).fit(X, y).predict(tes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rcm5vTJO1Kpb"
   },
   "source": [
    "### Averaging, Blending and Retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kPTGn86mktdP"
   },
   "outputs": [],
   "source": [
    "# Averaging the two stacked predictions from sklearn and vecstack in the ratio of 9:1\n",
    "#\n",
    "predictions_vecstack = [x*0.9 + y*0.1 for x, y in zip(predictions_vecstack, predictions_vecstack_2)]\n",
    "predictions_sreg = [x*0.9 + y*0.1 for x, y in zip(predictions_sreg, predictions_sreg_2)]\n",
    "\n",
    "\n",
    "# Blending the two ensemble models and the catboost single model\n",
    "#\n",
    "stack = [x*0.3 + y*0.7 for x, y in zip(predictions_vecstack, predictions_sreg)]\n",
    "stack_2 = [x*0.9 + y*0.1 for x, y in zip(stack, predictions_cat)]\n",
    "stack_3 = [x*0.7 + y*0.3 for x, y in zip(stack_2, predictions_feats)]\n",
    "\n",
    "\n",
    "# Retraining the models using the test data as training data and the predictions as the target\n",
    "#\n",
    "X = tes.copy()\n",
    "y = stack_3\n",
    "\n",
    "ridge = Ridge()\n",
    "ridge.fit(X, y)\n",
    "preds_ridge = ridge.predict(X)\n",
    "\n",
    "cat = CatBoostRegressor(verbose = False)\n",
    "cat.fit(X, y)\n",
    "preds_cat = cat.predict(X)\n",
    "# Blending the two trained models\n",
    "#\n",
    "blended_1 = [x*0.5 +y*0.5 for x, y in zip(preds_ridge, preds_cat)]\n",
    "\n",
    "\n",
    "\n",
    "# Retrainig the models using the above approach but using different weights\n",
    "#\n",
    "stack = [x*0.4 + y*0.6 for x, y in zip(predictions_vecstack, predictions_sreg)]\n",
    "stack_2 = [x*0.8 + y*0.2 for x, y in zip(stack, predictions_cat)]\n",
    "stack_3 = [x*0.65 + y*0.35 for x, y in zip(stack_2, predictions_feats)]\n",
    "\n",
    "X = tes.copy()\n",
    "y = stack_3\n",
    "\n",
    "ridge = Ridge()\n",
    "ridge.fit(X, y)\n",
    "preds_ridge = ridge.predict(X)\n",
    "\n",
    "cat = CatBoostRegressor(verbose = False)\n",
    "cat.fit(X, y)\n",
    "preds_cat = cat.predict(X)\n",
    "\n",
    "blended_2 = [x*0.5 +y*0.5 for x, y in zip(preds_ridge, preds_cat)]\n",
    "\n",
    "blended_3 = [x*0.9 + y*0.1 for x, y in zip(blended_1, blended_2)]\n",
    "\n",
    "\n",
    "# Further generalising the model by training using the simple Linear regression model\n",
    "# Complementing it with the catboost model\n",
    "#\n",
    "X = tes.copy()\n",
    "y = blended_3\n",
    "\n",
    "linear = LinearRegression()\n",
    "linear.fit(X, y)\n",
    "preds_linear = linear.predict(X)\n",
    "\n",
    "cat = CatBoostRegressor(verbose = False)\n",
    "cat.fit(X, y)\n",
    "preds_cat = cat.predict(X)\n",
    "\n",
    "\n",
    "# Blending the two model predictions\n",
    "# Creating a predictions file to be used in the next step, as you will have to restart the kernel\n",
    "#\n",
    "final_blend_1 = [x*0.1 + y*0.1 + z*0.8 for x, y, z in zip(preds_linear, preds_cat, blended_3)]\n",
    "sub_df = pd.DataFrame({'ward': test.ward, 'target': final_blend_1}) \n",
    "sub_df.to_csv('final_blend_1.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X5AZ9X5z3VPT"
   },
   "source": [
    "### More Ensembles for further regularisation\n",
    "### Train using latest version of catboost\n",
    "### **Restart kernel after installing the latest version of catboost**\n",
    "### *Run the notebook from the cell below after upgrading catboost*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132
    },
    "colab_type": "code",
    "id": "OouYHPp0oOAP",
    "outputId": "5b17058d-00dc-4f04-ca43-9cda1eb82d4c"
   },
   "outputs": [],
   "source": [
    "Upgrade catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "-9CsLMVFktT7",
    "outputId": "dbc22c5f-ed6c-44b0-9684-309ecf9f6eb8"
   },
   "outputs": [],
   "source": [
    "# Restart kernel after upgrading catboost and run notebook from this cell\n",
    "!pip install catboost --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "44p4hbTp4_NQ"
   },
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import StringIO \n",
    "import reverse_geocoder as rg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR, NuSVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor, XGBRFRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, BayesianRidge\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor,HistGradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from lightgbm import LGBMRegressor\n",
    "from vecstack import stacking\n",
    "from vecstack import StackingTransformer\n",
    "from catboost import CatBoostRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C89U6IRdktPp"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"Train.csv\")\n",
    "test = pd.read_csv(\"Test.csv\")\n",
    "submission = pd.read_csv(\"SampleSubmission.csv\")\n",
    "dictionary = pd.read_csv(\"variable_descriptions.csv\")\n",
    "\n",
    "\n",
    "# Creating a function to read a csv file shared via google\n",
    "#\n",
    "def read_csv(url):\n",
    "  url = 'https://drive.google.com/uc?export=download&id=' + url.split('/')[-2]\n",
    "  csv_raw = requests.get(url).text\n",
    "  csv = StringIO(csv_raw)\n",
    "  df = pd.read_csv(csv)\n",
    "  return df\n",
    "\n",
    "# Creating submission and training datataframes\n",
    "#\n",
    "#sub = read_csv(submission)\n",
    "#train = read_csv(train)\n",
    "#test = read_csv(test)\n",
    "#submission = read_csv(submission)\n",
    "#dictionary = read_csv(dictionary)\n",
    "\n",
    "target = train.target\n",
    "\n",
    "# Aligning the training and testing datasets\n",
    "train, test = train.align(test, join = 'inner', axis = 1)\n",
    "\n",
    "train['separator'] = 0\n",
    "test['separator'] = 1\n",
    "\n",
    "comb = pd.concat([train, test])\n",
    "\n",
    "train = comb[comb.separator == 0]\n",
    "test = comb[comb.separator == 1]\n",
    "\n",
    "train.drop('separator', axis = 1, inplace = True)\n",
    "test.drop('separator', axis = 1, inplace = True)\n",
    "train['target'] = target\n",
    "\n",
    "final_blend_1 = pd.read_csv('final_blend_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "srptKPtI3pfP"
   },
   "outputs": [],
   "source": [
    "# Training models using different random states and the latest catboost\n",
    "#\n",
    "X = train.drop(['ward', 'ADM4_PCODE', 'target'], axis = 1)\n",
    "y = target\n",
    "\n",
    "tes = test.drop(['ward', 'ADM4_PCODE'], axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 29)\n",
    "\n",
    "predictions_cat_29 = CatBoostRegressor(logging_level='Silent').fit(X_train, y_train).predict(tes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9KNf-sMf3pdu"
   },
   "outputs": [],
   "source": [
    "# Same as before with the only difference being the random state\n",
    "# Using different random states will ensure that all the data hase been used in bulding the model\n",
    "#\n",
    "X = train.drop(['ward', 'ADM4_PCODE', 'target'], axis = 1)\n",
    "y = target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 65)\n",
    "\n",
    "tes = test.drop(['ward', 'ADM4_PCODE'], axis = 1)\n",
    "\n",
    "estimators_1 = [\n",
    "    ('xgb', XGBRegressor(objective ='reg:squarederror')),\n",
    "    ('lr', LinearRegression()),\n",
    "    ('rf', RandomForestRegressor()),\n",
    "    ('lgb', LGBMRegressor()),\n",
    "    ('svr', SVR()),\n",
    "    ('lasso', Lasso()),\n",
    "    ('kneiba', KNeighborsRegressor()),\n",
    "    ('cat', CatBoostRegressor(logging_level='Silent'))\n",
    "]\n",
    "\n",
    "predictions_sreg_65 = StackingRegressor(estimators=estimators_1, final_estimator=CatBoostRegressor(logging_level='Silent')).fit(X_train, y_train).predict(tes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SkuuEvQ63pb1"
   },
   "outputs": [],
   "source": [
    "X = train.drop(['ward', 'ADM4_PCODE', 'target'], axis = 1)\n",
    "y = target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 27)\n",
    "\n",
    "tes = test.drop(['ward', 'ADM4_PCODE'], axis = 1)\n",
    "\n",
    "estimators_1 = [\n",
    "    ('xgb', XGBRegressor(objective ='reg:squarederror')),\n",
    "    ('lr', LinearRegression()),\n",
    "    ('rf', RandomForestRegressor()),\n",
    "    ('lgb', LGBMRegressor()),\n",
    "    ('svr', SVR()),\n",
    "    ('lasso', Lasso()),\n",
    "    ('kneiba', KNeighborsRegressor()),\n",
    "    ('cat', CatBoostRegressor(logging_level='Silent'))\n",
    "]\n",
    "\n",
    "predictions_sreg_27 = StackingRegressor(estimators=estimators_1, final_estimator=CatBoostRegressor(logging_level='Silent')).fit(X_train, y_train).predict(tes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Mf4Neos3pYs"
   },
   "outputs": [],
   "source": [
    "# Further averaging, blending and retraining to generalise well\n",
    "#\n",
    "stack = [x*0.5 + y*0.5 for x, y in zip(predictions_sreg_65, predictions_sreg_27)]\n",
    "\n",
    "stack_2 = [x*0.5 + y*0.5 for x, y in zip(stack, predictions_cat_29)]\n",
    "\n",
    "\n",
    "X = tes.copy()\n",
    "y = stack_2\n",
    "\n",
    "ridge = Ridge()\n",
    "ridge.fit(X, y)\n",
    "preds_ridge = ridge.predict(X)\n",
    "\n",
    "cat = CatBoostRegressor(verbose = False)\n",
    "cat.fit(X, y)\n",
    "preds_cat = cat.predict(X)\n",
    "\n",
    "final_blend_2 = [x*0.5 +y*0.5 for x, y in zip(preds_ridge, preds_cat)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dYWARbid3pVl"
   },
   "outputs": [],
   "source": [
    "# Making the final prediction\n",
    "#\n",
    "final_blend_3 = [x*0.5 + y*0.5 for x, y in zip(final_blend_1.target, final_blend_2)]\n",
    "sub_df = pd.DataFrame({'ward': test.ward, 'target': final_blend_3}) \n",
    "sub_df.to_csv('final_submission6.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7fgXhN_EGZJk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LucilleKaleha___Womxn_in_Big_Data_South_Africa_2nd_position___Solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
