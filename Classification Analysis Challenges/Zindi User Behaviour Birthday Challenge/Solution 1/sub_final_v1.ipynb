{"cells":[{"cell_type":"markdown","metadata":{"toc":true,"id":"HeGaV5E7pKid"},"source":["<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n","<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Loading-train-data\" data-toc-modified-id=\"Loading-train-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Loading train data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Merging-train-and-test-data\" data-toc-modified-id=\"Merging-train-and-test-data-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Merging train and test data</a></span></li><li><span><a href=\"#Merging-user-data\" data-toc-modified-id=\"Merging-user-data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Merging user data</a></span></li><li><span><a href=\"#Competitions-based-features\" data-toc-modified-id=\"Competitions-based-features-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Competitions based features</a></span></li><li><span><a href=\"#Competitions-data\" data-toc-modified-id=\"Competitions-data-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Competitions data</a></span></li><li><span><a href=\"#Time-based-competitions-features\" data-toc-modified-id=\"Time-based-competitions-features-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Time based competitions features</a></span></li><li><span><a href=\"#Current-active-competitions-feature\" data-toc-modified-id=\"Current-active-competitions-feature-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Current active competitions feature</a></span></li><li><span><a href=\"#User-Interests-Feature\" data-toc-modified-id=\"User-Interests-Feature-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>User Interests Feature</a></span></li><li><span><a href=\"#Submissions-based-features\" data-toc-modified-id=\"Submissions-based-features-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>Submissions based features</a></span></li><li><span><a href=\"#Discussion-based-features\" data-toc-modified-id=\"Discussion-based-features-1.9\"><span class=\"toc-item-num\">1.9&nbsp;&nbsp;</span>Discussion based features</a></span></li><li><span><a href=\"#Comments-based-features\" data-toc-modified-id=\"Comments-based-features-1.10\"><span class=\"toc-item-num\">1.10&nbsp;&nbsp;</span>Comments based features</a></span></li></ul></li><li><span><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Modeling</a></span></li><li><span><a href=\"#Submission\" data-toc-modified-id=\"Submission-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Submission</a></span></li></ul></div>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SIOo3an7pKiw"},"outputs":[],"source":["# !pip install -r requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sHlLUXZTpKi0"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2\n","\n","import os\n","import gc\n","import sys\n","import random\n","import pandas as pd\n","import numpy as np\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","\n","pd.set_option(\"max_colwidth\", None)\n","pd.set_option(\"max_columns\", 500)\n","pd.set_option(\"max_rows\", 500)\n","\n","plt.style.use('fivethirtyeight')\n","plt.rcParams[\"axes.labelsize\"] = 16\n","plt.rcParams[\"xtick.labelsize\"] = 14\n","plt.rcParams[\"ytick.labelsize\"] = 14\n","\n","from sklearn.model_selection import StratifiedKFold, GroupKFold\n","from catboost import CatBoostClassifier\n","from category_encoders import CountEncoder\n","import lightgbm as lgb\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P_saFM0NpKi4"},"outputs":[],"source":["class Config:\n","    LAG = 3\n","    VER = f'final_sub_v1'\n","    OUTPUT_DIR = './outputs'\n","    DATA_DIR = './data'\n","    DEBUG = True\n","    N_SPLITS = 5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X9gGVOXhpKi6"},"outputs":[],"source":["LOCAL_TEST_RUN = False\n","\n","def seed_everything(seed=0):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","\n","seed_everything()"]},{"cell_type":"markdown","metadata":{"id":"OVWDY8oKpKi7"},"source":["# Loading train data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3CrzSv5xpKi9"},"outputs":[],"source":["def determine_target(df):\n","    new_target = []\n","    for i, row in df.iterrows():\n","        if row['CompPart'] == 1:\n","            new_target.append('CompPart')\n","            continue\n","        elif row['Sub'] == 1 or row['Comment'] == 1 or row['Disc'] == 1:\n","            new_target.append('Sub')\n","            continue\n","        else:\n","            new_target.append('NoActivity')\n","        \n","    return new_target"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MEfA_shDpKjA","outputId":"349e89c2-8605-40dc-a91c-d0ea66e28e77"},"outputs":[{"name":"stdout","output_type":"stream","text":["(259832, 8)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>User_ID</th>\n","      <th>month</th>\n","      <th>year</th>\n","      <th>CompPart</th>\n","      <th>Comment</th>\n","      <th>Sub</th>\n","      <th>Disc</th>\n","      <th>Target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ID_XI7BAR4Y</td>\n","      <td>8</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NoActivity</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ID_XI7BAR4Y</td>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NoActivity</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ID_XI7BAR4Y</td>\n","      <td>9</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NoActivity</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ID_XI7BAR4Y</td>\n","      <td>9</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NoActivity</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ID_XI7BAR4Y</td>\n","      <td>10</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NoActivity</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       User_ID  month  year  CompPart  Comment  Sub  Disc      Target\n","0  ID_XI7BAR4Y      8     3         0        0    0     0  NoActivity\n","1  ID_XI7BAR4Y      8     2         0        0    0     0  NoActivity\n","2  ID_XI7BAR4Y      9     2         0        0    0     0  NoActivity\n","3  ID_XI7BAR4Y      9     3         0        0    0     0  NoActivity\n","4  ID_XI7BAR4Y     10     3         0        0    0     0  NoActivity"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["train = pd.read_csv(os.path.join(Config.DATA_DIR,\"Train.csv\"), index_col=None)\n","print(train.shape)\n","train['Target'] = determine_target(train)\n","train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"_52SDBsnpKjE","outputId":"56721dd0-90d1-4934-982d-e3cf77cd2bc0"},"outputs":[{"name":"stdout","output_type":"stream","text":["(65223, 3)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>User_ID</th>\n","      <th>month</th>\n","      <th>year</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ID_H1ELY25E</td>\n","      <td>1</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ID_H1ELY25E</td>\n","      <td>2</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ID_H1ELY25E</td>\n","      <td>3</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ID_463Q2BCO</td>\n","      <td>1</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ID_463Q2BCO</td>\n","      <td>2</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       User_ID  month  year\n","0  ID_H1ELY25E      1     4\n","1  ID_H1ELY25E      2     4\n","2  ID_H1ELY25E      3     4\n","3  ID_463Q2BCO      1     4\n","4  ID_463Q2BCO      2     4"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["if LOCAL_TEST_RUN:\n","    test_index = (train['year']==3)&(train['month'].isin([10,11,12]))\n","    test = train[test_index].reset_index(drop=True)\n","    train = train[~test_index].reset_index(drop=True)\n","else:\n","    test = pd.read_csv(os.path.join(Config.DATA_DIR,\"Test.csv\"), index_col=None)\n","\n","print(test.shape)\n","test.head()"]},{"cell_type":"markdown","metadata":{"id":"CT0LQBdYpKjG"},"source":["## Merging train and test data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rU2OnPBFpKjH","outputId":"961f4d46-8871-4c93-c2bf-cea7e315b729"},"outputs":[{"name":"stdout","output_type":"stream","text":["(259832, 8) (65223, 3)\n"]}],"source":["def determine_timestamp(df):\n","    df['year_month'] = (\n","        df['year'].astype(str) +\n","        df['month'].apply(lambda x: str(x).zfill(2))\n","    ).astype(int)\n","    df = df.sort_values(by='year_month').reset_index(drop=True)\n","    df['timestamp'] = np.arange(1, len(df) + 1)\n","\n","    return df\n","\n","print(train.shape, test.shape)\n","train['is_train'] = 1\n","test['is_train'] = 0\n","\n","overall = train.append(test, ignore_index=True)\n","timestamp = overall[['year', 'month']].drop_duplicates()\n","timestamp = determine_timestamp(timestamp)\n","overall = overall.merge(timestamp, how='left')\n","all_timestamps = overall[['User_ID', 'timestamp', 'year', 'month']].drop_duplicates().reset_index(drop=True)\n","\n","overall = overall.sort_values(by='timestamp').reset_index(drop=True)\n","overall['Record'] = 1\n","overall['Total_Num_User_Months'] = overall.groupby('User_ID')['Record'].apply(lambda x: x.cumsum())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"558UDbGCpKjI"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"YUQwtmX0pKjJ"},"source":["## Merging user data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FhjP1u5zpKjJ","outputId":"866b6f02-75bb-4997-acf0-e6194b7cbe87"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>User_ID</th>\n","      <th>FeatureX</th>\n","      <th>Country</th>\n","      <th>FeatureY</th>\n","      <th>Points</th>\n","      <th>Zindi_Joining_Timestamp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ID_N5LTBAPU</td>\n","      <td>0</td>\n","      <td>ID_DMRM</td>\n","      <td>1</td>\n","      <td>group 3</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ID_CLSFQB0S</td>\n","      <td>0</td>\n","      <td>ID_Q02</td>\n","      <td>3</td>\n","      <td>group 3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ID_RE6T58Y4</td>\n","      <td>0</td>\n","      <td>ID_Q02</td>\n","      <td>0</td>\n","      <td>group 3</td>\n","      <td>21</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ID_XJQQRJV3</td>\n","      <td>0</td>\n","      <td>ID_Z8BI</td>\n","      <td>0</td>\n","      <td>group 3</td>\n","      <td>18</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ID_1JHU6A8S</td>\n","      <td>0</td>\n","      <td>ID_Q02</td>\n","      <td>3</td>\n","      <td>group 3</td>\n","      <td>19</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       User_ID  FeatureX  Country  FeatureY   Points  Zindi_Joining_Timestamp\n","0  ID_N5LTBAPU         0  ID_DMRM         1  group 3                       13\n","1  ID_CLSFQB0S         0   ID_Q02         3  group 3                        2\n","2  ID_RE6T58Y4         0   ID_Q02         0  group 3                       21\n","3  ID_XJQQRJV3         0  ID_Z8BI         0  group 3                       18\n","4  ID_1JHU6A8S         0   ID_Q02         3  group 3                       19"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["users = pd.read_csv(os.path.join(Config.DATA_DIR,\"Users.csv\"), index_col=None)\n","users.columns = ['User_ID', 'FeatureX', 'Country', 'FeatureY', 'Points', 'year', 'month', 'dayofweek']\n","users = users.merge(timestamp, how='left')\n","users = users.rename(columns={\"timestamp\": \"Zindi_Joining_Timestamp\"})\n","users.drop(['dayofweek', 'year', 'month', 'year_month'], axis=1, inplace=True)\n","users.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"euhSwCSwpKjK"},"outputs":[],"source":["overall = overall.merge(users, how='left')\n","\n","sel_cols = ['FeatureX', 'Country', 'FeatureY', 'Points']\n","overall[sel_cols] = overall[sel_cols].astype(str)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q1fUzQsApKjL"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"g3TgZoAvpKjL"},"source":["## Competitions based features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r_BUVk1kpKjL"},"outputs":[],"source":["usr_comp = pd.read_csv(os.path.join(Config.DATA_DIR,\"CompetitionPartipation.csv\"), index_col=None)\n","usr_comp.columns = ['CompID', 'User_ID', 'PublicRank', 'Successful_Sub_Count',\n","                    'year', 'month', 'dayofweek']\n","if LOCAL_TEST_RUN:\n","    test_index = (usr_comp['year']==3)&(usr_comp['month'].isin([10,11,12]))\n","    usr_comp = usr_comp[~test_index].reset_index(drop=True)\n","    \n","usr_comp_timestamp = usr_comp.merge(timestamp, how='left')\n","usr_comp_timestamp = usr_comp_timestamp[['User_ID', 'month', 'year', 'timestamp']].drop_duplicates()\n","usr_comp_timestamp.columns = ['User_ID', 'month', 'year', 'comp_timestamp']\n","overall = overall.merge(usr_comp_timestamp, how='left')\n","\n","overall = overall.sort_values(by='timestamp').reset_index(drop=True)\n","overall['comp_timestamp'] = overall.groupby('User_ID')['comp_timestamp'].apply(lambda x: x.ffill().shift())\n","overall['Months_Since_Last_Comp'] = overall['timestamp'] - overall['comp_timestamp']\n","overall['Months_Since_Joining_Zindi'] = overall['comp_timestamp'] - overall['Zindi_Joining_Timestamp']"]},{"cell_type":"markdown","metadata":{"id":"HpjD6lsYpKjM"},"source":["## Competitions data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ADasEzBJpKjM"},"outputs":[],"source":["competitions = pd.read_csv(os.path.join(Config.DATA_DIR,\"Competitions.csv\"),\n","                           index_col=None,\n","                           skipinitialspace=True)\n","competitions['CompEndTime Year'] = [int(val) if val!='not mapped' else 999 for val in competitions['CompEndTime Year']]\n","competitions['FeatureC'] = competitions['FeatureC'].fillna(-1).astype(np.int8)\n","competitions = competitions.merge(\n","    timestamp,\n","    left_on=['CompStartTime Year', 'CompStartTime Month'],\n","    right_on=['year', 'month'],\n","    how='left')\n","competitions = competitions.rename(columns={\n","    'timestamp': 'comp_start_timestamp',\n","})\n","competitions.drop(['year', 'month', 'year_month'], axis=1, inplace=True)\n","competitions = competitions.merge(\n","    timestamp,\n","    left_on=['CompEndTime Year', 'CompEndTime Month'],\n","    right_on=['year', 'month'],\n","    how='left')\n","competitions = competitions.rename(columns={\n","    'timestamp': 'comp_end_timestamp',\n","})\n","competitions['comp_end_timestamp'] = competitions['comp_end_timestamp'].fillna(99)\n","competitions.drop(['year', 'month', 'year_month'], axis=1, inplace=True)\n","competitions['comp_duration'] = competitions['comp_end_timestamp'] - competitions['comp_start_timestamp']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Szt2gghApKjM"},"outputs":[],"source":["import ast\n","for col in ['FeatureA', 'FeatureB', 'FeatureE']:\n","    competitions[col] = competitions[col].map(ast.literal_eval)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mIDZVKWfpKjN"},"outputs":[],"source":["comp_features = competitions[['CompID']].copy()\n","for col in ['FeatureA', 'FeatureB', 'FeatureC', 'FeatureD', 'FeatureE']:\n","    tmp = competitions[['CompID', col]].explode(column=[col])\n","    tmp[col] = tmp[col].fillna('empty')\n","    tmp['count'] = 1\n","\n","    tmp = tmp.pivot_table(index='CompID', \n","                    columns=col,\n","                    values='count',\n","                    aggfunc='count')\n","    tmp.columns = [tmp.columns.name + \"_\" + str(col) for col in tmp.columns]\n","    tmp = tmp.reset_index()\n","    comp_features = comp_features.merge(tmp, how='left')\n","comp_features = comp_features.fillna(0)\n","comp_features = comp_features.merge(competitions[['CompID', 'comp_start_timestamp']])"]},{"cell_type":"markdown","metadata":{"id":"CxCa0tKIpKjN"},"source":["## Time based competitions features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"he7t3whipKjN","outputId":"7115d0f4-3b44-4881-bf35-0bf0928a9859"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 2398.73it/s]\n"]}],"source":["timestamp_ids = []\n","competitions_ids = []\n","for t in tqdm(timestamp.timestamp):\n","    selected_comp = competitions.CompID[(t>=competitions.comp_start_timestamp)&(t<=competitions.comp_end_timestamp)]\n","    timestamp_ids.extend([t]*len(selected_comp))\n","    competitions_ids.extend(selected_comp)\n","\n","timestamp_comp = pd.DataFrame({\n","    \"timestamp\": timestamp_ids,\n","    \"CompID\": competitions_ids\n","})"]},{"cell_type":"markdown","metadata":{"id":"GmKwdg6NpKjO"},"source":["## Current active competitions feature"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LxJZ-2tWpKjO"},"outputs":[],"source":["active_comp = usr_comp.merge(timestamp, how='left')\n","active_comp = active_comp.rename(columns={\"timestamp\": \"comp_timestamp\"})\n","active_comp = active_comp[['User_ID', 'CompID', 'comp_timestamp']].merge(competitions[['CompID', 'comp_start_timestamp', 'comp_end_timestamp']], how='left')\n","active_comp = active_comp[active_comp['comp_end_timestamp']!=99].reset_index(drop=True)\n","active_comp = all_timestamps.merge(active_comp, how='left')\n","\n","active_comp['Current_Active_Competitions'] = (\n","    (active_comp['timestamp'] > active_comp['comp_timestamp']) &\n","    (active_comp['timestamp'] <= active_comp['comp_end_timestamp'])\n",").astype(np.int8)\n","\n","active_comp = active_comp.groupby(['User_ID', 'timestamp'])['Current_Active_Competitions'].sum()\n","active_comp = active_comp.reset_index()\n","\n","overall = overall.merge(active_comp, how='left')"]},{"cell_type":"markdown","metadata":{"id":"GQb_v8mNpKjO"},"source":["## User Interests Feature"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xd5-mt4qpKjP","outputId":"79a59e75-b4c5-4564-9c96-436c0b0e29c9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['FeatureA_1', 'FeatureA_2', 'FeatureA_3', 'FeatureA_4', 'FeatureA_5',\n","       'FeatureA_6', 'FeatureA_7', 'FeatureA_8', 'FeatureA_9', 'FeatureA_10',\n","       'FeatureA_empty', 'FeatureB_5', 'FeatureB_6', 'FeatureB_7',\n","       'FeatureB_8', 'FeatureB_9', 'FeatureB_10', 'FeatureB_12', 'FeatureB_14',\n","       'FeatureB_15', 'FeatureB_16', 'FeatureB_empty', 'FeatureC_-1',\n","       'FeatureC_1', 'FeatureC_2', 'FeatureC_3', 'FeatureC_4', 'FeatureC_5',\n","       'FeatureC_6', 'FeatureC_7', 'FeatureC_8', 'FeatureC_9', 'FeatureC_10',\n","       'FeatureC_11', 'FeatureC_12', 'FeatureC_13', 'FeatureC_14',\n","       'FeatureC_15', 'FeatureC_16', 'FeatureC_17', 'FeatureC_18',\n","       'FeatureC_19', 'FeatureC_20', 'FeatureC_21', 'FeatureC_22',\n","       'FeatureC_23', 'FeatureC_24', 'FeatureC_25', 'FeatureC_26',\n","       'FeatureC_27', 'FeatureC_28', 'FeatureC_29', 'FeatureC_30',\n","       'FeatureC_31', 'FeatureC_32', 'FeatureC_33', 'FeatureC_34',\n","       'FeatureC_35', 'FeatureC_36', 'FeatureC_37', 'FeatureD_1', 'FeatureD_2',\n","       'FeatureD_3', 'FeatureE_1', 'FeatureE_2', 'FeatureE_3', 'FeatureE_4',\n","       'FeatureE_5', 'FeatureE_6', 'FeatureE_7', 'FeatureE_8', 'FeatureE_9',\n","       'FeatureE_10', 'FeatureE_empty'],\n","      dtype='object')\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 74/74 [03:14<00:00,  2.63s/it]\n"]}],"source":["timestamp_comp = timestamp_comp.merge(comp_features, how='left')\n","timestamp_comp.drop(['comp_start_timestamp', 'CompID'], axis=1, inplace=True)\n","timestamp_comp = timestamp_comp.groupby('timestamp').agg(np.sum).reset_index()\n","timestamp_comp = timestamp_comp.sort_values('timestamp').reset_index(drop=True)\n","\n","usr_comp_timestamp = usr_comp.merge(timestamp, how='left')\n","usr_comp_features = usr_comp_timestamp[['User_ID', 'CompID', 'timestamp']].merge(comp_features, how='left')\n","usr_comp_features = usr_comp_features.drop(['CompID', 'comp_start_timestamp'], axis=1)\n","usr_comp_features = usr_comp_features.groupby(['User_ID', 'timestamp']).agg(np.sum)#.groupby(level=0).cumsum()\n","usr_comp_features = usr_comp_features.reset_index()\n","usr_comp_features = all_timestamps.merge(usr_comp_features, how='left')\n","sel_cols = usr_comp_features.columns[4:]\n","print(sel_cols)\n","\n","usr_comp_features = usr_comp_features.sort_values(by='timestamp').reset_index(drop=True)\n","for col in tqdm(sel_cols):\n","    usr_comp_features[col] = usr_comp_features.groupby('User_ID')[col].apply(lambda x: x.ffill())\n","\n","usr_comp_features = usr_comp_features.fillna(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jEGIW8fUpKjP"},"outputs":[],"source":["from sklearn.metrics.pairwise import cosine_similarity\n","\n","timestamp_ids = []\n","usr_ids = []\n","user_interests = []\n","\n","for t in timestamp_comp['timestamp']:\n","    if t == 1:\n","        continue\n","    usr_f = usr_comp_features[usr_comp_features['timestamp']==t-1]\n","    timestamp_ids.extend([t]*len(usr_f))\n","    usr_ids.extend(usr_f.pop('User_ID'))\n","    \n","    comp_f = timestamp_comp[timestamp_comp['timestamp']==t]\n","    usr_f.drop(['timestamp', 'year', 'month'], axis=1, inplace=True)\n","    comp_f.drop('timestamp', axis=1, inplace=True)\n","    \n","    interests = np.matmul(usr_f.values, comp_f.values.T).flatten()\n","#     interests = cosine_similarity(usr_f.values, comp_f.values).flatten()\n","    user_interests.extend(interests)\n","\n","usr_interest_f = pd.DataFrame({\n","    \"timestamp\": timestamp_ids,\n","    \"User_ID\": usr_ids,\n","    \"user_interests\": user_interests\n","})\n","\n","overall = overall.merge(usr_interest_f, how='left')\n","overall = overall.sort_values(by='timestamp').reset_index(drop=True)\n","overall['user_interests'] = overall.groupby('User_ID')['user_interests'].apply(lambda x: x.ffill())\n","overall['user_interests'] = overall['user_interests'].fillna(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T5tRD4BnpKjQ"},"outputs":[],"source":["comp_hist = usr_comp.groupby(['User_ID', 'year', 'month'])['CompID'].nunique()\n","comp_hist = comp_hist.reset_index()\n","comp_hist.columns = [*comp_hist.columns[:-1]] + ['Num_Comp_Prev_Month']\n","\n","overall = overall.merge(comp_hist, how='left')\n","overall = overall.sort_values(by=['User_ID', 'timestamp']).reset_index(drop=True)\n","overall['Num_Comp_Prev_Month'] = overall['Num_Comp_Prev_Month'].fillna(0)\n","overall['Num_Comp_Per_Month'] = overall.groupby('User_ID')['Num_Comp_Prev_Month'].cumsum()\n","overall['Num_Comp_Per_Month_trend'] = overall['Num_Comp_Per_Month']/overall['Total_Num_User_Months']\n","overall['Num_Comp_Per_Month_trend'] = overall.groupby('User_ID')['Num_Comp_Per_Month_trend'].apply(lambda x: x.shift())\n","overall['Num_Comp_Per_Month'] = overall['Num_Comp_Per_Month']/(overall['timestamp'].max() - overall['Zindi_Joining_Timestamp'])\n","overall['Num_Comp_Per_Month'] = overall.groupby('User_ID')['Num_Comp_Per_Month'].apply(lambda x: x.shift())\n","\n","overall['Num_Comp_Prev_Month'] = overall.groupby('User_ID')['Num_Comp_Prev_Month'].apply(lambda x: x.shift())\n","overall['Num_Comp_Prev_Month_momentum'] = overall['Num_Comp_Prev_Month'] - overall.groupby('User_ID')['Num_Comp_Prev_Month'].apply(lambda x: x.shift(1))\n","overall['Num_Comp_Prev_Month_momentum2'] = overall['Num_Comp_Prev_Month'] - overall.groupby('User_ID')['Num_Comp_Prev_Month'].apply(lambda x: x.shift(2))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PpveS_OSpKjQ"},"outputs":[],"source":["tmp = usr_comp.groupby(['User_ID', 'year', 'month', 'PublicRank'])['CompID'].nunique().unstack('PublicRank').apply(lambda x: x/x.sum(), axis=1)\n","col_names = [tmp.columns.name + \"_\" + str(col) for col in tmp.columns]\n","tmp.columns = col_names\n","tmp = tmp.fillna(0)\n","tmp = tmp.reset_index()\n","\n","tmp = all_timestamps.merge(tmp, how='left')\n","tmp = tmp.sort_values(by='timestamp').reset_index(drop=True)\n","for col in col_names:\n","    tmp[col] = tmp.groupby('User_ID')[col].apply(lambda x: x.cumsum().ffill().shift())\n","    \n","overall = overall.merge(tmp, how='left')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_o0TwT__pKjQ"},"outputs":[],"source":["tmp = usr_comp.groupby(['User_ID', 'year', 'month', 'Successful_Sub_Count'])['CompID'].nunique().unstack('Successful_Sub_Count').apply(lambda x: x/x.sum(), axis=1)\n","col_names = [tmp.columns.name + \"_\" + str(col) for col in tmp.columns]\n","tmp.columns = col_names\n","tmp = tmp.fillna(0)\n","tmp = tmp.reset_index()\n","\n","tmp = all_timestamps.merge(tmp, how='left')\n","tmp = tmp.sort_values(by='timestamp').reset_index(drop=True)\n","for col in col_names:\n","    tmp[col] = tmp.groupby('User_ID')[col].apply(lambda x: x.cumsum().ffill().shift())\n","    \n","overall = overall.merge(tmp, how='left')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DdUCEhdjpKjQ","outputId":"82c1a11a-e04f-4386-c8de-463982326abb"},"outputs":[{"data":{"text/plain":["0"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["del usr_comp, usr_comp_timestamp, comp_hist\n","gc.collect()"]},{"cell_type":"markdown","metadata":{"id":"xeh8hpPzpKjR"},"source":["## Submissions based features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yfkbyVb7pKjR"},"outputs":[],"source":["usr_sub = pd.read_csv(os.path.join(Config.DATA_DIR,\"Submissions.csv\"), index_col=None)\n","usr_sub.columns = ['User_ID', 'FeatureG', 'CompID', 'year', 'month', 'dayofweek']\n","\n","if LOCAL_TEST_RUN:\n","    test_index = (usr_sub['year']==3)&(usr_sub['month'].isin([10,11,12]))\n","    usr_sub = usr_sub[~test_index].reset_index(drop=True)\n","    \n","usr_sub_timestamp = usr_sub.merge(timestamp, how='left')\n","usr_sub_timestamp = usr_sub_timestamp[['User_ID', 'month', 'year', 'timestamp']].drop_duplicates()\n","usr_sub_timestamp.columns = ['User_ID', 'month', 'year', 'sub_timestamp']\n","overall = overall.merge(usr_sub_timestamp, how='left')\n","\n","overall = overall.sort_values(by='timestamp').reset_index(drop=True)\n","overall['sub_timestamp'] = overall.groupby('User_ID')['sub_timestamp'].apply(lambda x: x.ffill().shift())\n","overall['Months_Since_Last_Sub'] = overall['timestamp'] - overall['sub_timestamp']\n","overall['Months_Since_Sub_Joining_Zindi'] = overall['sub_timestamp'] - overall['Zindi_Joining_Timestamp']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M7GmJxZ7pKjS"},"outputs":[],"source":["sub_hist = usr_sub.groupby(['User_ID', 'year', 'month']).agg({'CompID': ['nunique', 'count']})\n","sub_hist.columns = [\"_\".join(col) for col in sub_hist.columns]\n","sub_hist['Sub_Per_Comp'] = sub_hist['CompID_nunique']/sub_hist['CompID_count']\n","sub_hist.drop(['CompID_nunique', 'CompID_count'], axis=1, inplace=True)\n","sub_hist = sub_hist.reset_index()\n","sub_hist.columns = [*sub_hist.columns[:-1]] + ['Num_Sub_Prev_Month']\n","\n","overall = overall.merge(sub_hist, how='left')\n","overall = overall.sort_values(by=['User_ID', 'timestamp']).reset_index(drop=True)\n","overall['Num_Sub_Prev_Month'] = overall['Num_Sub_Prev_Month'].fillna(0)\n","overall['Num_Sub_Per_Month'] = overall.groupby('User_ID')['Num_Sub_Prev_Month'].cumsum()\n","overall['Num_Sub_Per_Month_trend'] = overall['Num_Sub_Per_Month']/overall['Total_Num_User_Months']\n","overall['Num_Sub_Per_Month_trend'] = overall.groupby('User_ID')['Num_Sub_Per_Month_trend'].apply(lambda x: x.shift())\n","overall['Num_Sub_Per_Month'] = overall['Num_Sub_Per_Month']/(overall['timestamp'].max() - overall['Zindi_Joining_Timestamp'])\n","overall['Num_Sub_Per_Month'] = overall.groupby('User_ID')['Num_Sub_Per_Month'].apply(lambda x: x.shift())\n","\n","overall['Num_Sub_Prev_Month'] = overall.groupby('User_ID')['Num_Sub_Prev_Month'].apply(lambda x: x.shift())\n","overall['Num_Sub_Prev_Month_momentum'] = overall['Num_Sub_Prev_Month'] - overall.groupby('User_ID')['Num_Sub_Prev_Month'].apply(lambda x: x.shift(1))\n","overall['Num_Sub_Prev_Month_momentum2'] = overall['Num_Sub_Prev_Month'] - overall.groupby('User_ID')['Num_Sub_Prev_Month'].apply(lambda x: x.shift(2))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UKR4U5NEpKjS"},"outputs":[],"source":["tmp = usr_sub.groupby(['User_ID', 'year', 'month', 'FeatureG'])['CompID'].nunique().unstack('FeatureG')#.apply(lambda x: x/x.sum(), axis=1)\n","col_names = [tmp.columns.name + \"_\" + str(col) for col in tmp.columns]\n","tmp.columns = col_names\n","tmp = tmp.fillna(0)\n","tmp = tmp.reset_index()\n","\n","all_timestamps = overall[['User_ID', 'timestamp', 'year', 'month']].drop_duplicates().reset_index(drop=True)\n","tmp = all_timestamps.merge(tmp, how='left')\n","tmp = tmp.sort_values(by='timestamp').reset_index(drop=True)\n","for col in col_names:\n","    tmp[col] = tmp.groupby('User_ID')[col].apply(lambda x: x.ffill().shift())\n","    \n","overall = overall.merge(tmp, how='left')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pPJZx88TpKjS","outputId":"066e77be-d9b4-4d67-b97c-8436c123a269"},"outputs":[{"data":{"text/plain":["0"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["del usr_sub, usr_sub_timestamp, sub_hist\n","gc.collect()"]},{"cell_type":"markdown","metadata":{"id":"hcCt8NHSpKjT"},"source":["## Discussion based features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YjZSa6B_pKjT"},"outputs":[],"source":["usr_dis = pd.read_csv(os.path.join(Config.DATA_DIR,\"Discussions.csv\"), index_col=None)\n","usr_dis.columns = ['FeatureF', 'year', 'month', 'dayofweek', 'DiscID', 'User_ID']\n","\n","if LOCAL_TEST_RUN:\n","    test_index = (usr_dis['year']==3)&(usr_dis['month'].isin([10,11,12]))\n","    usr_dis = usr_dis[~test_index].reset_index(drop=True)\n","    \n","usr_dis_timestamp = usr_dis.merge(timestamp, how='left')\n","usr_dis_timestamp = usr_dis_timestamp[['User_ID', 'month', 'year', 'timestamp']].drop_duplicates()\n","usr_dis_timestamp.columns = ['User_ID', 'month', 'year', 'discussion_timestamp']\n","overall = overall.merge(usr_dis_timestamp, how='left')\n","\n","overall = overall.sort_values(by='timestamp').reset_index(drop=True)\n","overall['discussion_timestamp'] = overall.groupby('User_ID')['discussion_timestamp'].apply(lambda x: x.ffill().shift())\n","overall['Months_Since_Last_Dis'] = overall['timestamp'] - overall['discussion_timestamp']\n","overall['Months_Since_Dis_Joining_Zindi'] = overall['discussion_timestamp'] - overall['Zindi_Joining_Timestamp']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jSdUvrClpKjT"},"outputs":[],"source":["dis_hist = usr_dis.groupby(['User_ID', 'year', 'month'])['DiscID'].nunique()\n","dis_hist = dis_hist.reset_index()\n","dis_hist.columns = [*dis_hist.columns[:-1]] + ['Num_Dis_Prev_Month']\n","\n","overall = overall.merge(dis_hist, how='left')\n","overall = overall.sort_values(by=['User_ID', 'timestamp']).reset_index(drop=True)\n","overall['Num_Dis_Prev_Month'] = overall['Num_Dis_Prev_Month'].fillna(0)\n","overall['Num_Dis_Per_Month'] = overall.groupby('User_ID')['Num_Dis_Prev_Month'].cumsum()\n","overall['Num_Dis_Per_Month_trend'] = overall['Num_Dis_Per_Month']/overall['Total_Num_User_Months']\n","overall['Num_Dis_Per_Month_trend'] = overall.groupby('User_ID')['Num_Dis_Per_Month_trend'].apply(lambda x: x.shift())\n","overall['Num_Dis_Per_Month'] = overall['Num_Dis_Per_Month']/(overall['timestamp'].max() - overall['Zindi_Joining_Timestamp'])\n","overall['Num_Dis_Per_Month'] = overall.groupby('User_ID')['Num_Dis_Per_Month'].apply(lambda x: x.shift())\n","\n","overall['Num_Dis_Prev_Month'] = overall.groupby('User_ID')['Num_Dis_Prev_Month'].apply(lambda x: x.shift())\n","overall['Num_Dis_Prev_Month_momentum'] = overall['Num_Dis_Prev_Month'] - overall.groupby('User_ID')['Num_Dis_Prev_Month'].apply(lambda x: x.shift(1))\n","overall['Num_Dis_Prev_Month_momentum2'] = overall['Num_Dis_Prev_Month'] - overall.groupby('User_ID')['Num_Dis_Prev_Month'].apply(lambda x: x.shift(2))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TBKwfW-wpKjU","outputId":"9cd38002-be4e-44cd-fc00-3e7bf4ef15de"},"outputs":[{"data":{"text/plain":["0"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["del usr_dis, usr_dis_timestamp, dis_hist\n","gc.collect()"]},{"cell_type":"markdown","metadata":{"id":"xEK3yvfZpKjV"},"source":["## Comments based features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oHSafsObpKjV"},"outputs":[],"source":["usr_comments = pd.read_csv(os.path.join(Config.DATA_DIR,\"Comments.csv\"), index_col=None)\n","usr_comments.columns = ['User_ID', 'year', 'month', 'dayofweek']\n","usr_comments['CommID'] = np.arange(len(usr_comments))\n","\n","if LOCAL_TEST_RUN:\n","    test_index = (usr_comments['year']==3)&(usr_comments['month'].isin([10,11,12]))\n","    usr_comments = usr_comments[~test_index].reset_index(drop=True)\n","    \n","usr_comm_timestamp = usr_comments.merge(timestamp, how='left')\n","usr_comm_timestamp = usr_comm_timestamp[['User_ID', 'month', 'year', 'timestamp']].drop_duplicates()\n","usr_comm_timestamp.columns = ['User_ID', 'month', 'year', 'comment_timestamp']\n","overall = overall.merge(usr_comm_timestamp, how='left')\n","\n","overall = overall.sort_values(by='timestamp').reset_index(drop=True)\n","overall['comment_timestamp'] = overall.groupby('User_ID')['comment_timestamp'].apply(lambda x: x.ffill().shift())\n","overall['Months_Since_Last_Comment'] = overall['timestamp'] - overall['comment_timestamp']\n","overall['Months_Since_Comment_Joining_Zindi'] = overall['comment_timestamp'] - overall['Zindi_Joining_Timestamp']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jEt9sXNQpKjV"},"outputs":[],"source":["comm_hist = usr_comments.groupby(['User_ID', 'year', 'month'])['CommID'].nunique()\n","comm_hist = comm_hist.reset_index()\n","comm_hist.columns = [*comm_hist.columns[:-1]] + ['Num_Comm_Prev_Month']\n","\n","overall = overall.merge(comm_hist, how='left')\n","overall = overall.sort_values(by=['User_ID', 'timestamp']).reset_index(drop=True)\n","overall['Num_Comm_Prev_Month'] = overall['Num_Comm_Prev_Month'].fillna(0)\n","overall['Num_Comm_Per_Month'] = overall.groupby('User_ID')['Num_Comm_Prev_Month'].cumsum()\n","overall['Num_Comm_Per_Month_trend'] = overall['Num_Comm_Per_Month']/overall['Total_Num_User_Months']\n","overall['Num_Comm_Per_Month_trend'] = overall.groupby('User_ID')['Num_Comm_Per_Month_trend'].apply(lambda x: x.shift())\n","overall['Num_Comm_Per_Month'] = overall['Num_Comm_Per_Month']/(overall['timestamp'].max() - overall['Zindi_Joining_Timestamp'])\n","overall['Num_Comm_Per_Month'] = overall.groupby('User_ID')['Num_Comm_Per_Month'].apply(lambda x: x.shift())\n","\n","overall['Num_Comm_Prev_Month'] = overall.groupby('User_ID')['Num_Comm_Prev_Month'].apply(lambda x: x.shift())\n","overall['Num_Comm_Prev_Month_momentum'] = overall['Num_Comm_Prev_Month'] - overall.groupby('User_ID')['Num_Comm_Prev_Month'].apply(lambda x: x.shift(1))\n","overall['Num_Comm_Prev_Month_momentum2'] = overall['Num_Comm_Prev_Month'] - overall.groupby('User_ID')['Num_Comm_Prev_Month'].apply(lambda x: x.shift(2))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vBML-9h2pKjW","outputId":"966bdaf1-9d6f-491b-ce54-cf6697ab15f8"},"outputs":[{"data":{"text/plain":["0"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["del usr_comments, usr_comm_timestamp, comm_hist\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"enYikVbHpKjW"},"outputs":[],"source":["tmp = overall.groupby('timestamp').agg({\n","    \"User_ID\": [\"nunique\"],\n","    \"Total_Num_User_Months\": [\"mean\", \"max\", \"std\"],\n","})\n","tmp.columns = [\"_\".join(col) for col in tmp.columns]\n","tmp = tmp.reset_index()\n","\n","overall = overall.merge(tmp, how='left')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GeU6EBEkpKjW"},"outputs":[],"source":["sel_cols = ['Months_Since_Last_Comp', 'Months_Since_Last_Dis', 'Months_Since_Last_Sub', 'Months_Since_Last_Comment']\n","overall['Months_Since_Last_Activity_Mean'] = overall[sel_cols].std(axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IQxT3kHKpKjX"},"outputs":[],"source":["time_cols = [\n","    'Zindi_Joining_Timestamp',\n","    'comment_timestamp',\n","    'comp_timestamp',\n","    'discussion_timestamp',\n","    'sub_timestamp',\n","    'Months_Since_Last_Comp',\n","    'Months_Since_Last_Sub',\n","    'Months_Since_Last_Dis',\n","    'Months_Since_Last_Comment',\n","]\n","\n","for col in time_cols:\n","    overall[col] = overall[col]/overall['timestamp']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NwRzGSIfpKjX"},"outputs":[],"source":["tmp_time = overall[overall['Zindi_Joining_Timestamp']==1]\n","tmp_time = tmp_time.groupby('timestamp')['User_ID'].nunique().to_frame(\"unique_user_count\")\n","tmp_time = tmp_time.reset_index()\n","\n","overall = overall.merge(tmp_time, how='left')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A2jUtX35pKjX"},"outputs":[],"source":["overall['user_interests_rank'] = overall.groupby('timestamp')['user_interests'].apply(lambda x: \n","                                                                                      x.rank(method='dense', ascending=False))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4tukgImUpKjX","outputId":"aad581d7-463c-46dc-c028-40f6bb8e0e44"},"outputs":[{"name":"stdout","output_type":"stream","text":["(259832, 9) (65223, 4)\n","(259832, 81) (65223, 81)\n"]}],"source":["# overall.loc[overall['user_interests']==0, 'user_interests'] = np.NaN\n","print(train.shape, test.shape)\n","train, test = overall[overall['is_train']==1], overall[overall['is_train']==0]\n","print(train.shape, test.shape)"]},{"cell_type":"markdown","metadata":{"id":"b7Vb1q7mpKjX"},"source":["# Modeling"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PEGN2TVKpKjY"},"outputs":[],"source":["def train_model(df_trainX, df_trainY, df_evalX, df_evalY, cat_cols, model_name='CAT', params=None):\n","    from sklearn.metrics import roc_auc_score\n","    if model_name == 'CAT':\n","        if params is None:\n","            params={'n_estimators':10000,'random_state':123,'cat_features':cat_cols}\n","        clf=CatBoostClassifier(**params,early_stopping_rounds=50,eval_metric='AUC')\n","        clf.fit(df_trainX,df_trainY,eval_set=(df_evalX,df_evalY),plot=False, verbose=50)\n","        valid_score = clf.get_best_score().get('validation').get('AUC')\n","        best_iteration = clf.get_best_iteration()\n","        feature_score = clf.get_feature_importance()\n","    elif model_name == 'LGB':\n","        if params is None:\n","            params={'verbose':0,'n_estimators':10000,'random_state':123,'learning_rate':0.01,'force_row_wise':True,'colsample_bytree':0.3}\n","        clf = lgb.LGBMClassifier(**params, importance_type='gain', metric='auc_mu', num_leaves=127, min_child_samples=5)\n","        callbacks = [lgb.early_stopping(500, verbose=0)]\n","        clf.fit(df_trainX,\n","                df_trainY,#)\n","                eval_set=[(df_evalX, df_evalY)],\n","                callbacks=callbacks,\n","                verbose=0\n","               )\n","\n","        valid_score = roc_auc_score(df_evalY!='NoActivity', 1-clf.predict_proba(df_evalX)[:,1])\n","        best_iteration = clf.booster_.best_iteration\n","        feature_score = clf.feature_importances_\n","    return clf, valid_score, best_iteration, feature_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lZQB7DItpKjY"},"outputs":[],"source":["train.to_csv(os.path.join(Config.DATA_DIR,\"Train_fe.csv.gz\"), compression='gzip')\n","test.to_csv(os.path.join(Config.DATA_DIR,\"Test_fe.csv.gz\"), compression='gzip')"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"ydwQrBe5pKjY","outputId":"e91499d3-b087-43e4-8bf6-a71c1ce646a6"},"outputs":[{"name":"stdout","output_type":"stream","text":["[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n","[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n","Fold 1 0.9050635572161991 at 668\n","[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n","[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n","Fold 2 0.9044670487830438 at 913\n","[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n","[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n","Fold 3 0.9080523301191019 at 424\n","[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n","[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n","Fold 4 0.9024576875811107 at 746\n","[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n","[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n","Fold 5 0.9081277085785924 at 1184\n","The local CV is 0.9056389319496082\n","CPU times: user 1h 6min 33s, sys: 1min 3s, total: 1h 7min 36s\n","Wall time: 6min 6s\n"]}],"source":["%%time\n","\n","drop_cols = [\n","    'year', 'month', 'Target', 'Sub', 'CompPart', 'Comment', 'Disc',\n","    'is_train', 'timestamp', 'Record', 'Active_Month', 'Total_Num_User_Months',\n","    'user_interests'\n","]\n","cat_cols = list(\n","    set(train.columns[train.dtypes == 'object']) - set(drop_cols) - set(['User_ID'])\n",")\n","num_cols = list(set(train.columns) - set(cat_cols + drop_cols))\n","\n","train_X = train[cat_cols + num_cols]\n","train_X[cat_cols] = train_X[cat_cols].astype('category')\n","train_Y = train['Target']\n","\n","test_X = test[cat_cols + num_cols]\n","test_X[cat_cols] = test_X[cat_cols].astype('category')\n","\n","fold = GroupKFold(n_splits=5)\n","cb_scores, pred_cb, feat_scores = [], [], []\n","for it, (idxT, idxV) in enumerate(\n","        fold.split(train_X, train_Y, groups=train['timestamp'])):\n","    df_trainX, df_trainY = train_X.iloc[idxT], train_Y.iloc[idxT]\n","    df_evalX, df_evalY = train_X.iloc[idxV], train_Y.iloc[idxV]\n","    df_testX = test_X.copy()\n","\n","    selected_cat_cols = ['Country']\n","    cat_cols_count = [f'{col}_count' for col in selected_cat_cols]\n","    df_trainX[cat_cols_count] = df_trainX[selected_cat_cols].copy()\n","    df_evalX[cat_cols_count] = df_evalX[selected_cat_cols].copy()\n","    df_testX[cat_cols_count] = df_testX[selected_cat_cols].copy()\n","\n","    encoder = CountEncoder(cols=cat_cols_count + ['User_ID'])\n","    df_trainX = encoder.fit_transform(df_trainX, df_trainY)\n","    df_evalX = encoder.transform(df_evalX)\n","    df_testX = encoder.transform(df_testX)\n","\n","    clf, valid_score, best_iteration, feature_score = train_model(\n","        df_trainX, df_trainY, df_evalX, df_evalY, cat_cols, model_name='LGB')\n","    cb_scores.append(valid_score)\n","    pred_cb.append(clf.predict_proba(df_testX)[:, 1])\n","    feat_scores.append(feature_score)\n","    print('Fold {} {} at {}'.format(it + 1, valid_score, best_iteration))\n","\n","weights = cb_scores / sum(np.array(cb_scores))\n","print('The local CV is {}'.format(np.sum(weights * cb_scores)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RAEXY6wMpKjZ"},"outputs":[],"source":["if LOCAL_TEST_RUN:\n","    weights=cb_scores/sum(np.array(cb_scores))\n","    print ('The local CV is {}'.format(np.sum(weights*cb_scores)))\n","\n","    prediction = np.sum(weights*np.transpose(pred_cb),1)\n","    from sklearn.metrics import roc_auc_score\n","    print(\"Test score is {}\".format(roc_auc_score(test['Target']!='NoActivity', 1-prediction)))"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"7ThOV_tDpKjZ","outputId":"8c3ac2e0-9b99-4867-e0c0-30ee2cc27e39"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>feature</th>\n","      <th>importance</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Num_Comp_Prev_Month</td>\n","      <td>9.037149</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Num_Sub_Prev_Month</td>\n","      <td>9.007915</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Num_Comp_Per_Month_trend</td>\n","      <td>8.885045</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Num_Comp_Per_Month</td>\n","      <td>7.023674</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Points</td>\n","      <td>4.678487</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Current_Active_Competitions</td>\n","      <td>4.198269</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Zindi_Joining_Timestamp</td>\n","      <td>3.375272</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>sub_timestamp</td>\n","      <td>3.290834</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Country</td>\n","      <td>2.535924</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Months_Since_Last_Comp</td>\n","      <td>2.481734</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Months_Since_Last_Sub</td>\n","      <td>2.284014</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>user_interests_rank</td>\n","      <td>2.080107</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>User_ID_nunique</td>\n","      <td>2.078042</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>comp_timestamp</td>\n","      <td>2.011407</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>Num_Comm_Prev_Month</td>\n","      <td>1.875548</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>Num_Comm_Per_Month_trend</td>\n","      <td>1.765395</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>Months_Since_Joining_Zindi</td>\n","      <td>1.723902</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>Num_Sub_Prev_Month_momentum</td>\n","      <td>1.713266</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>User_ID</td>\n","      <td>1.663058</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>Country_count</td>\n","      <td>1.526995</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>Num_Comm_Per_Month</td>\n","      <td>1.425225</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>Months_Since_Sub_Joining_Zindi</td>\n","      <td>1.260742</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>Total_Num_User_Months_mean</td>\n","      <td>1.257454</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>Num_Sub_Per_Month</td>\n","      <td>1.222074</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>Num_Comp_Prev_Month_momentum</td>\n","      <td>1.181587</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>unique_user_count</td>\n","      <td>1.163326</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>Num_Dis_Prev_Month</td>\n","      <td>1.152274</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>Successful_Sub_Count_count 10</td>\n","      <td>1.128178</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>Num_Sub_Per_Month_trend</td>\n","      <td>1.104089</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>Total_Num_User_Months_std</td>\n","      <td>1.094354</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>FeatureG_1</td>\n","      <td>0.964176</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>Num_Sub_Prev_Month_momentum2</td>\n","      <td>0.903752</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>year_month</td>\n","      <td>0.752662</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>Months_Since_Last_Activity_Mean</td>\n","      <td>0.740189</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>FeatureX</td>\n","      <td>0.707856</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>Num_Dis_Per_Month</td>\n","      <td>0.645148</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>Num_Comp_Prev_Month_momentum2</td>\n","      <td>0.621522</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>comment_timestamp</td>\n","      <td>0.552447</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>Successful_Sub_Count_count 6</td>\n","      <td>0.504908</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>Num_Comm_Prev_Month_momentum</td>\n","      <td>0.498088</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>PublicRank_rank 11</td>\n","      <td>0.492490</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>discussion_timestamp</td>\n","      <td>0.472571</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>Total_Num_User_Months_max</td>\n","      <td>0.438610</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>Successful_Sub_Count_count 3</td>\n","      <td>0.422899</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>FeatureG_0</td>\n","      <td>0.406344</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>FeatureY</td>\n","      <td>0.371450</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>Months_Since_Last_Comment</td>\n","      <td>0.347444</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>Num_Dis_Prev_Month_momentum</td>\n","      <td>0.346420</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>Months_Since_Comment_Joining_Zindi</td>\n","      <td>0.341968</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>Num_Dis_Per_Month_trend</td>\n","      <td>0.322711</td>\n","    </tr>\n","    <tr>\n","      <th>50</th>\n","      <td>Months_Since_Last_Dis</td>\n","      <td>0.310982</td>\n","    </tr>\n","    <tr>\n","      <th>51</th>\n","      <td>Successful_Sub_Count_count 8</td>\n","      <td>0.304535</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>Successful_Sub_Count_count 7</td>\n","      <td>0.300377</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>Successful_Sub_Count_count 9</td>\n","      <td>0.296907</td>\n","    </tr>\n","    <tr>\n","      <th>54</th>\n","      <td>PublicRank_rank 1</td>\n","      <td>0.272648</td>\n","    </tr>\n","    <tr>\n","      <th>55</th>\n","      <td>Num_Comm_Prev_Month_momentum2</td>\n","      <td>0.259996</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>Months_Since_Dis_Joining_Zindi</td>\n","      <td>0.258565</td>\n","    </tr>\n","    <tr>\n","      <th>57</th>\n","      <td>Successful_Sub_Count_count 5</td>\n","      <td>0.202630</td>\n","    </tr>\n","    <tr>\n","      <th>58</th>\n","      <td>FeatureG_3</td>\n","      <td>0.199760</td>\n","    </tr>\n","    <tr>\n","      <th>59</th>\n","      <td>PublicRank_rank 9</td>\n","      <td>0.195073</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>PublicRank_rank 10</td>\n","      <td>0.190304</td>\n","    </tr>\n","    <tr>\n","      <th>61</th>\n","      <td>Successful_Sub_Count_count 4</td>\n","      <td>0.179139</td>\n","    </tr>\n","    <tr>\n","      <th>62</th>\n","      <td>PublicRank_rank 2</td>\n","      <td>0.160982</td>\n","    </tr>\n","    <tr>\n","      <th>63</th>\n","      <td>Num_Dis_Prev_Month_momentum2</td>\n","      <td>0.155268</td>\n","    </tr>\n","    <tr>\n","      <th>64</th>\n","      <td>PublicRank_rank 5</td>\n","      <td>0.136916</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>PublicRank_rank 8</td>\n","      <td>0.129792</td>\n","    </tr>\n","    <tr>\n","      <th>66</th>\n","      <td>PublicRank_rank 7</td>\n","      <td>0.122258</td>\n","    </tr>\n","    <tr>\n","      <th>67</th>\n","      <td>PublicRank_rank 3</td>\n","      <td>0.099241</td>\n","    </tr>\n","    <tr>\n","      <th>68</th>\n","      <td>PublicRank_rank 6</td>\n","      <td>0.086978</td>\n","    </tr>\n","    <tr>\n","      <th>69</th>\n","      <td>PublicRank_rank 4</td>\n","      <td>0.058654</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                               feature  importance\n","0                  Num_Comp_Prev_Month    9.037149\n","1                   Num_Sub_Prev_Month    9.007915\n","2             Num_Comp_Per_Month_trend    8.885045\n","3                   Num_Comp_Per_Month    7.023674\n","4                               Points    4.678487\n","5          Current_Active_Competitions    4.198269\n","6              Zindi_Joining_Timestamp    3.375272\n","7                        sub_timestamp    3.290834\n","8                              Country    2.535924\n","9               Months_Since_Last_Comp    2.481734\n","10               Months_Since_Last_Sub    2.284014\n","11                 user_interests_rank    2.080107\n","12                     User_ID_nunique    2.078042\n","13                      comp_timestamp    2.011407\n","14                 Num_Comm_Prev_Month    1.875548\n","15            Num_Comm_Per_Month_trend    1.765395\n","16          Months_Since_Joining_Zindi    1.723902\n","17         Num_Sub_Prev_Month_momentum    1.713266\n","18                             User_ID    1.663058\n","19                       Country_count    1.526995\n","20                  Num_Comm_Per_Month    1.425225\n","21      Months_Since_Sub_Joining_Zindi    1.260742\n","22          Total_Num_User_Months_mean    1.257454\n","23                   Num_Sub_Per_Month    1.222074\n","24        Num_Comp_Prev_Month_momentum    1.181587\n","25                   unique_user_count    1.163326\n","26                  Num_Dis_Prev_Month    1.152274\n","27       Successful_Sub_Count_count 10    1.128178\n","28             Num_Sub_Per_Month_trend    1.104089\n","29           Total_Num_User_Months_std    1.094354\n","30                          FeatureG_1    0.964176\n","31        Num_Sub_Prev_Month_momentum2    0.903752\n","32                          year_month    0.752662\n","33     Months_Since_Last_Activity_Mean    0.740189\n","34                            FeatureX    0.707856\n","35                   Num_Dis_Per_Month    0.645148\n","36       Num_Comp_Prev_Month_momentum2    0.621522\n","37                   comment_timestamp    0.552447\n","38        Successful_Sub_Count_count 6    0.504908\n","39        Num_Comm_Prev_Month_momentum    0.498088\n","40                  PublicRank_rank 11    0.492490\n","41                discussion_timestamp    0.472571\n","42           Total_Num_User_Months_max    0.438610\n","43        Successful_Sub_Count_count 3    0.422899\n","44                          FeatureG_0    0.406344\n","45                            FeatureY    0.371450\n","46           Months_Since_Last_Comment    0.347444\n","47         Num_Dis_Prev_Month_momentum    0.346420\n","48  Months_Since_Comment_Joining_Zindi    0.341968\n","49             Num_Dis_Per_Month_trend    0.322711\n","50               Months_Since_Last_Dis    0.310982\n","51        Successful_Sub_Count_count 8    0.304535\n","52        Successful_Sub_Count_count 7    0.300377\n","53        Successful_Sub_Count_count 9    0.296907\n","54                   PublicRank_rank 1    0.272648\n","55       Num_Comm_Prev_Month_momentum2    0.259996\n","56      Months_Since_Dis_Joining_Zindi    0.258565\n","57        Successful_Sub_Count_count 5    0.202630\n","58                          FeatureG_3    0.199760\n","59                   PublicRank_rank 9    0.195073\n","60                  PublicRank_rank 10    0.190304\n","61        Successful_Sub_Count_count 4    0.179139\n","62                   PublicRank_rank 2    0.160982\n","63        Num_Dis_Prev_Month_momentum2    0.155268\n","64                   PublicRank_rank 5    0.136916\n","65                   PublicRank_rank 8    0.129792\n","66                   PublicRank_rank 7    0.122258\n","67                   PublicRank_rank 3    0.099241\n","68                   PublicRank_rank 6    0.086978\n","69                   PublicRank_rank 4    0.058654"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["featureImp=pd.DataFrame({'feature':df_trainX.columns,'importance':np.mean(np.array(feat_scores),0)})\n","featureImp=featureImp.sort_values('importance',ascending=False)\n","featureImp['importance']=featureImp['importance']*100/featureImp['importance'].sum()\n","featureImp.reset_index(drop=True)"]},{"cell_type":"markdown","metadata":{"id":"HBGnf3MOpKjZ"},"source":["# Submission "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PJP0dBPEpKja"},"outputs":[],"source":["test['Target'] = np.sum(weights * np.transpose(pred_cb), 1)\n","test['Target'] = 1 - test['Target']\n","test['UserMonthYear'] = test['User_ID'] + \"_\" + test['month'].astype(str) + \"_\" + test['year'].astype(str)\n","test[['UserMonthYear', 'Target']].to_csv(os.path.join(Config.OUTPUT_DIR, f'{Config.VER}.csv'), index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kT87EP8_pKja","outputId":"30a6b1cd-9d89-4d81-d442-f6467a98ef56"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>UserMonthYear</th>\n","      <th>Target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>13</th>\n","      <td>ID_000VV0KM_1_4</td>\n","      <td>0.014111</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>ID_000VV0KM_2_4</td>\n","      <td>0.014824</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>ID_000VV0KM_3_4</td>\n","      <td>0.010529</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>ID_003OCIYO_1_4</td>\n","      <td>0.328175</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>ID_003OCIYO_2_4</td>\n","      <td>0.017162</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>325041</th>\n","      <td>ID_ZZVPF22K_2_4</td>\n","      <td>0.161856</td>\n","    </tr>\n","    <tr>\n","      <th>325042</th>\n","      <td>ID_ZZVPF22K_3_4</td>\n","      <td>0.108418</td>\n","    </tr>\n","    <tr>\n","      <th>325052</th>\n","      <td>ID_ZZXDLYXB_1_4</td>\n","      <td>0.008774</td>\n","    </tr>\n","    <tr>\n","      <th>325053</th>\n","      <td>ID_ZZXDLYXB_2_4</td>\n","      <td>0.008380</td>\n","    </tr>\n","    <tr>\n","      <th>325054</th>\n","      <td>ID_ZZXDLYXB_3_4</td>\n","      <td>0.008036</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>65223 rows × 2 columns</p>\n","</div>"],"text/plain":["          UserMonthYear    Target\n","13      ID_000VV0KM_1_4  0.014111\n","14      ID_000VV0KM_2_4  0.014824\n","15      ID_000VV0KM_3_4  0.010529\n","16      ID_003OCIYO_1_4  0.328175\n","17      ID_003OCIYO_2_4  0.017162\n","...                 ...       ...\n","325041  ID_ZZVPF22K_2_4  0.161856\n","325042  ID_ZZVPF22K_3_4  0.108418\n","325052  ID_ZZXDLYXB_1_4  0.008774\n","325053  ID_ZZXDLYXB_2_4  0.008380\n","325054  ID_ZZXDLYXB_3_4  0.008036\n","\n","[65223 rows x 2 columns]"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["test[['UserMonthYear', 'Target']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ewL_ToArpKja"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.11"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":true,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"349.091px"},"toc_section_display":true,"toc_window_display":true},"colab":{"name":"sub_final_v1.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}