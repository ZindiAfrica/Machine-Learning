{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ToVaccineOrNotVaccine.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "rsuS6j8JaokB",
        "w1X13z0e-ZZt",
        "yhJHW1q3dX82",
        "YQ3eS5h4gtYr"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA2ysoWJEnP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsuS6j8JaokB",
        "colab_type": "text"
      },
      "source": [
        "#Requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atlSSh7wJvUp",
        "colab_type": "code",
        "outputId": "da649df5-571a-459a-bbae-ce42cd843dcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%%writefile setup.sh\n",
        "\n",
        "export CUD_HOME=/usr/local/cuda-10.1\n",
        "git clone https://github.com/NVIDIA/apex\n",
        "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting setup.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9cRoAcHKLIT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For apex\n",
        "# !sh setup.sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX-nG5z4ZEka",
        "colab_type": "code",
        "outputId": "ea6d4731-a32f-49d8-d248-391965492f1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "!pip install transformers --quiet"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 573kB 2.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0MB 8.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 16.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.7MB 25.6MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFP9Vvbfa6ww",
        "colab_type": "text"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juBoFMWpbiC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sY0t1LMbY7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import gc\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UuQDTtadkdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPWKBEHyM6RG",
        "colab_type": "code",
        "outputId": "f5f97295-c770-4118-eb75-9c1535b773f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KHCLbBabvUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8scAB3Ba9j5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import transformers\n",
        "from transformers import (AutoTokenizer, AutoModel, AdamW, AutoConfig, get_linear_schedule_with_warmup)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1X13z0e-ZZt",
        "colab_type": "text"
      },
      "source": [
        "#Envs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I7sCm5J-atk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 2020 # for reproductibility\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "if torch.cuda.is_available(): \n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO4JywCqRwKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.makedirs('MODELS/', exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUA0ZEK5eiHj",
        "colab_type": "text"
      },
      "source": [
        "#Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTLKw0dQfRbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_prediction(preds):\n",
        "  r'''\n",
        "    This function helps us go from a classifiaction\n",
        "    problem to a regression one.\n",
        "    The regression values range are in [-1, 1].\n",
        "  '''\n",
        "\n",
        "  final_preds = []\n",
        "  for pred in preds:\n",
        "    argmax = np.argmax(pred, axis=0)\n",
        "    if argmax == 0: final_preds.append( -1*pred[0] )\n",
        "    elif argmax == 1: final_preds.append( 0 )\n",
        "    else: final_preds.append( pred[2] )\n",
        "    \n",
        "  return final_preds\n",
        "\n",
        "\n",
        "def rmse(true, pred):\n",
        "  return np.sqrt(mean_squared_error(true, pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nji2bkWhkRqN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_examples(tweets, tokenizer, max_length): \n",
        "  bep = tokenizer.batch_encode_plus(tweets, add_special_tokens=True, max_length=max_length, \n",
        "                                    pad_to_max_length=True, return_token_type_ids=True,\n",
        "                                    return_attention_masks=True)\n",
        "  \n",
        "  return bep['input_ids'], bep['token_type_ids'], bep['attention_mask']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U9bIQagD-rP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EarlyStopping:\n",
        "  def __init__(self, patience=3, mode='min'):\n",
        "    self.step = 0\n",
        "    self.patience = patience\n",
        "    self.mode = mode\n",
        "    self.stop = False\n",
        "    self.loss = np.inf\n",
        "\n",
        "  def update(self, loss):\n",
        "    if self.loss < loss:\n",
        "      self.step += 1\n",
        "    else: \n",
        "      self.step = 0\n",
        "      self.loss = loss\n",
        "    \n",
        "    if self.step == self.patience: self.stop = True "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bshiJdrXU50q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VaccineOrNotModel(nn.Module):\n",
        "    def __init__(self, model_name):\n",
        "        super(VaccineOrNotModel, self).__init__()\n",
        "\n",
        "        config = AutoConfig.from_pretrained(model_name)\n",
        "        self.model = AutoModel.from_pretrained(model_name, config=config)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(config.hidden_size, 3)\n",
        "        nn.init.xavier_normal_(self.classifier.weight)\n",
        "    \n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
        "        _, out = self.model(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids\n",
        "        )\n",
        "\n",
        "        out = self.dropout(out)\n",
        "        logits = self.classifier(out)\n",
        "        logits = F.sigmoid(logits)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j_oVpLtg3Zw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VaccineOrNotDataset(Dataset):\n",
        "  def __init__(self, input_ids, att_masks, token_ids, labels=None, task='train', classes=3):\n",
        "    self.input_ids = input_ids\n",
        "    self.att_masks = att_masks\n",
        "    self.token_ids = token_ids\n",
        "    self.labels = labels\n",
        "    self.c = classes\n",
        "    self.task = task\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, id):\n",
        "    out = {\n",
        "        'input_ids': torch.tensor(self.input_ids[id]),\n",
        "        'token_type_ids': torch.tensor(self.token_ids[id]),\n",
        "        'attention_mask': torch.tensor(self.att_masks[id]),\n",
        "    }\n",
        "\n",
        "    if self.task=='train': \n",
        "      out.update(\n",
        "        {\n",
        "          'label': torch.tensor(to_categorical(self.labels[id]+1, self.c), dtype=torch.float), #The former labels are in [-1, 1], so we add +1 to be in [0, 2]\n",
        "        }\n",
        "      )\n",
        "\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFJBRysz1-nL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training_fn(model, opt, scheduler, criterion, train_ds, bs, device='cuda', n_labels=3):\n",
        "  train_dl = DataLoader(train_ds, bs)\n",
        "\n",
        "  avg_rmse = 0\n",
        "  avg_loss = 0\n",
        "\n",
        "  pbar = tqdm(train_dl, desc='Training ...')\n",
        "  model.train()\n",
        "\n",
        "  for i, data in enumerate(pbar):\n",
        "    input_ids = data['input_ids'].to(device)\n",
        "    attention_mask = data['attention_mask'].to(device)\n",
        "    token_type_ids = data['token_type_ids'].to(device)\n",
        "    labels = data['label'].to(device)\n",
        "\n",
        "    opt.zero_grad()\n",
        "\n",
        "    logits = model(input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        token_type_ids=token_type_ids)\n",
        "        \n",
        "    loss = criterion(logits, labels)\n",
        "    custom_loss = rmse( labels.cpu().detach().numpy().argmax(1)-1, process_prediction(logits.cpu().detach().numpy()) )\n",
        "\n",
        "    avg_loss += loss.item()\n",
        "    avg_rmse += custom_loss\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    opt.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    pbar.set_postfix(loss=avg_loss/(i+1), rmse=avg_rmse/(i+1))\n",
        "    pbar.update()\n",
        "\n",
        "  return avg_rmse/len(train_dl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv8oNxIv1_iw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_fn(model, criterion, valid_ds, eval_bs, device='cuda', n_labels=3):\n",
        "  valid_dl = DataLoader(valid_ds, eval_bs)\n",
        "\n",
        "  avg_rmse = 0\n",
        "  avg_loss = 0\n",
        "\n",
        "  pbar = tqdm(valid_dl, desc='Evaluation ...')\n",
        "  model.eval()\n",
        "\n",
        "  for i, data in enumerate(pbar):\n",
        "    input_ids = data['input_ids'].to(device)\n",
        "    attention_mask = data['attention_mask'].to(device)\n",
        "    token_type_ids = data['token_type_ids'].to(device)\n",
        "    labels = data['label'].to(device)\n",
        "\n",
        "    logits = model(input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        token_type_ids=token_type_ids\n",
        "        )\n",
        "    \n",
        "\n",
        "    loss = criterion(logits, labels)\n",
        "    \n",
        "    custom_loss = rmse( labels.cpu().detach().numpy().argmax(1)-1, process_prediction(logits.cpu().detach().numpy()) )\n",
        "\n",
        "    avg_loss += loss.item()\n",
        "    avg_rmse += custom_loss\n",
        "\n",
        "    pbar.set_postfix(loss=avg_loss/(i+1), rmse=avg_rmse/(i+1))\n",
        "    pbar.update()\n",
        "\n",
        "  return avg_rmse/len(valid_dl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ2X7soJ_xxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(input_ids, mask, token_ids, MODELS, bs=8, n_labels=3):\n",
        "    test_ds = VaccineOrNotDataset(input_ids, mask, token_ids, task='test')\n",
        "    testloader = DataLoader(test_ds, bs, shuffle=False)\n",
        "\n",
        "    predictions_proba = []\n",
        "\n",
        "    out = None\n",
        "\n",
        "    for data in tqdm(testloader):\n",
        "        x = data['input_ids'].to(device)\n",
        "\n",
        "        for i in range(n_folds):\n",
        "            if i == 0: out = MODELS[i](input_ids=x)\n",
        "            else: out += MODELS[i](input_ids=x)\n",
        "\n",
        "        out /= n_folds\n",
        "        out_probas = out.cpu().detach().numpy()\n",
        "\n",
        "        predictions_proba += out_probas.tolist()\n",
        "\n",
        "    return predictions_proba\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_57a6pl6r3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_by_fold(model, input_ids, mask, token_ids, bs=8, n_labels=3):\n",
        "    test_ds = VaccineOrNotDataset(input_ids, mask, token_ids, task='test')\n",
        "    testloader = DataLoader(test_ds, bs, shuffle=False)\n",
        "\n",
        "    predictions_proba = []\n",
        "\n",
        "    out = None\n",
        "\n",
        "    for data in tqdm(testloader):\n",
        "        x = data['input_ids'].to(device)\n",
        "        \n",
        "        out = model(input_ids=x)\n",
        "\n",
        "        out /= n_folds\n",
        "        out_probas = out.cpu().detach().numpy()\n",
        "\n",
        "        predictions_proba += out_probas.tolist()\n",
        "\n",
        "    return predictions_proba\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t1GZvHP3rT8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_fold(fold, epochs, splits, bs, eval_bs, lr, model_name, path='MODELS/'):\n",
        "  tr, vr = splits\n",
        "  train_ds = VaccineOrNotDataset(np.take(tr_ids, tr, axis=0), np.take(tr_masks,tr, axis=0),\n",
        "                                np.take(tr_tokens,tr, axis=0), np.take(train_labels,tr, axis=0)) \n",
        "  valid_ds = VaccineOrNotDataset(np.take(tr_ids, vr, axis=0), np.take(tr_masks,vr, axis=0),\n",
        "                                np.take(tr_tokens,vr, axis=0), np.take(train_labels,vr, axis=0)) \n",
        "\n",
        "  train_dl = DataLoader(train_ds, bs)\n",
        "  valid_dl = DataLoader(valid_ds, eval_bs)\n",
        "\n",
        "  device='cuda'\n",
        "\n",
        "  model = VaccineOrNotModel(model_name)\n",
        "  model.to(device)\n",
        "\n",
        "  num_train_steps = int(len(train_ds) / bs*epochs)\n",
        "\n",
        "  param_optimizer = list(model.named_parameters())\n",
        "  no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "  optimizer_parameters = [\n",
        "      {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
        "      {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
        "  ]\n",
        "\n",
        "  opt = AdamW(optimizer_parameters, lr=lr)\n",
        "  scheduler = get_linear_schedule_with_warmup(\n",
        "            opt, num_warmup_steps=0, num_training_steps=num_train_steps\n",
        "        )\n",
        "\n",
        "  criterion = nn.BCELoss()\n",
        "  es = EarlyStopping(patience=3)\n",
        "\n",
        "  best_rmse = np.inf\n",
        "\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    training_fn(model, opt, scheduler, criterion, train_ds, bs, device)\n",
        "    score = eval_fn(model, criterion, valid_ds, eval_bs, device)\n",
        "    es.update(score)\n",
        "\n",
        "    if score < best_rmse:\n",
        "      best_rmse = score\n",
        "      torch.save(model.state_dict(), f'{path}model_state_dict_{fold}.bin')\n",
        "\n",
        "    if es.stop:\n",
        "      print(\"Early Stopping triggered\")\n",
        "      return best_rmse\n",
        "      \n",
        "  return best_rmse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhJHW1q3dX82",
        "colab_type": "text"
      },
      "source": [
        "#Reading the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RZcXsKZddEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = 'drive/My Drive/Zindi/#ZindiWeekendz/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AspysT1ca8_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(path+'Train.csv')\n",
        "test = pd.read_csv(path+'Test.csv')\n",
        "sample = pd.read_csv(path+'SampleSubmission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ3eS5h4gtYr",
        "colab_type": "text"
      },
      "source": [
        "#Cleaning and Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhNbxGVxi64H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = 'roberta-large'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RofU7BuFgv7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OryYhzsnG1To",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['safe_text'] = train['safe_text'].apply(str)\n",
        "test['safe_text'] = test['safe_text'].apply(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jGq8_mUHy_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['safe_text'] = train['safe_text'].apply(str.lower)\n",
        "test['safe_text'] = test['safe_text'].apply(str.lower)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8YNkYQUG9i2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['safe_text'] = train['safe_text'].apply(lambda x: x.replace('&amp;', ' '))\n",
        "test['safe_text'] = test['safe_text'].apply(lambda x: x.replace('&amp;', ' '))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3UuAZm0CYf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['safe_text'] = train['safe_text'].apply(lambda x: x.replace('<user>', ' '))\n",
        "test['safe_text'] = test['safe_text'].apply(lambda x: x.replace('<user>', ' '))\n",
        "\n",
        "train['safe_text'] = train['safe_text'].apply(lambda x: x.replace('<url>', ' '))\n",
        "test['safe_text'] = test['safe_text'].apply(lambda x: x.replace('<url>', ' '))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TngQMlh6bJw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['safe_text'] = train['safe_text'].apply(lambda x: x.replace('#', ' '))\n",
        "test['safe_text'] = test['safe_text'].apply(lambda x: x.replace('#', ' '))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pr7QJhNDHaP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['safe_text'] = train['safe_text'].apply(lambda x: x.strip('.').strip())\n",
        "test['safe_text'] = test['safe_text'].apply(lambda x: x.strip('.').strip())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xtttcYRZqv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.drop(index=[4798, 4799], inplace=True)\n",
        "train.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbIIbyFpCuja",
        "colab_type": "code",
        "outputId": "d5f5cad7-8899-4a9b-f397-776948e79b4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>safe_text</th>\n",
              "      <th>label</th>\n",
              "      <th>agreement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CL1KWCMY</td>\n",
              "      <td>me   the big homie meanboy3000  meanboy  mb  m...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>E3303EME</td>\n",
              "      <td>i'm 100% thinking of devoting my career to pro...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M4IVFSMS</td>\n",
              "      <td>whatcausesautism vaccines, do not vaccinate yo...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1DR6ROZ4</td>\n",
              "      <td>i mean if they immunize my kid with something ...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>J77ENIIE</td>\n",
              "      <td>thanks to   catch me performing at la nuit nyc...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tweet_id  ... agreement\n",
              "0  CL1KWCMY  ...       1.0\n",
              "1  E3303EME  ...       1.0\n",
              "2  M4IVFSMS  ...       1.0\n",
              "3  1DR6ROZ4  ...       1.0\n",
              "4  J77ENIIE  ...       1.0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prk5WGKagwrI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_text = train['safe_text'].values\n",
        "train_labels = train['label'].values\n",
        "\n",
        "test_text = test['safe_text'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIroAINVsVFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_ids, tr_tokens, tr_masks = convert_examples(train_text, tokenizer, max_length=34)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPH-m6iYs_EV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "te_ids, te_tokens, te_masks = convert_examples(test_text, tokenizer, max_length=34)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzmc4dFFgxHb",
        "colab_type": "text"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a7ho5I_4zKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#These Hyperparameters could be tune\n",
        "epochs = 10\n",
        "n_folds = 10\n",
        "bs = 32\n",
        "eval_bs = 4\n",
        "lr = 3e-5\n",
        "device = 'cuda'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHBUICfJ3LUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "skf = StratifiedKFold(n_folds, shuffle=True, random_state=seed)\n",
        "all_folds = list(skf.split(tr_ids, train_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mb47-o44x78j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv_score = 0\n",
        "for fold in range(n_folds):\n",
        "  splits = all_folds[fold]\n",
        "\n",
        "  s = run_fold(fold, epochs, splits, bs, eval_bs, lr, model_name=model_name)\n",
        "  cv_score += s/n_folds\n",
        "print(\"Avg rmse : \", cv_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilrM4KAw-t4Q",
        "colab_type": "text"
      },
      "source": [
        "#Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keqCNlnG0hJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Just to cool down the memory :)\n",
        "del train,tokenizer,tr_ids,tr_masks,tr_tokens\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWji_OY4-w8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = []\n",
        "\n",
        "for fold in range(n_folds):\n",
        "  model = VaccineOrNotModel(model_name)\n",
        "  model.to(device)\n",
        "  model.load_state_dict(torch.load(f'MODELS/model_state_dict_{fold}.bin'))\n",
        "  model.eval()\n",
        "\n",
        "  preds.append( predict_on_fold(model, te_ids, te_masks, te_tokens, bs=8) )\n",
        "\n",
        "  del model\n",
        "  gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lshLLtah_n5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_proba = np.sum(preds, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oacey_BD_n2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = process_prediction(predictions_proba) #Final step"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MDkKnf6CLVG",
        "colab_type": "text"
      },
      "source": [
        "#Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b8C2DRw_nzC",
        "colab_type": "code",
        "outputId": "919143d3-86f6-48d3-d458-0595d2acc066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "subs = test[['tweet_id']]\n",
        "subs['target'] = predictions\n",
        "subs.columns = ['ID', 'target']\n",
        "subs.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00BHHHP1</td>\n",
              "      <td>-0.518568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00UNMD0E</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>01AXPTJF</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01HOEQJW</td>\n",
              "      <td>0.921080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>01JUKMAO</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         ID    target\n",
              "0  00BHHHP1 -0.518568\n",
              "1  00UNMD0E  0.000000\n",
              "2  01AXPTJF  0.000000\n",
              "3  01HOEQJW  0.921080\n",
              "4  01JUKMAO  0.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRoFH8R3_nwR",
        "colab_type": "code",
        "outputId": "fc20e2a0-ad2b-49a0-ac3a-b8032f584595",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "subs.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5177.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.305531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.480103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-0.886795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.841104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.935912</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            target\n",
              "count  5177.000000\n",
              "mean      0.305531\n",
              "std       0.480103\n",
              "min      -0.886795\n",
              "25%       0.000000\n",
              "50%       0.000000\n",
              "75%       0.841104\n",
              "max       0.935912"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm_zHVYf_nm2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subs.to_csv(f'arch_{model_name}_folds_{n_folds}_epochs_{epochs}_bs_{bs}_lr_{lr}_cv_{cv_score}.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubFnZn3BsaMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}