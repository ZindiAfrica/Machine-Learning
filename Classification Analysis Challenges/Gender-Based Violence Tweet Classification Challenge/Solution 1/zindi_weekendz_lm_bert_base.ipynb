{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"zindi_weekendz_lm_bert_base.ipynb","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"code","metadata":{"id":"DiuXFHtA8SAX","executionInfo":{"status":"ok","timestamp":1628861335236,"user_tz":-180,"elapsed":417,"user":{"displayName":"Cedric Manouan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnI55k9QnJV4mtok5wRGE36cZcj1DZIjihnSx6=s64","userId":"00242929915047742214"}}},"source":["# !pip install --upgrade simpletransformers\n","# # !pip install --upgrade torch\n","# !pip install --upgrade transformers"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SATDJUJSomR3","executionInfo":{"status":"ok","timestamp":1628861339901,"user_tz":-180,"elapsed":3983,"user":{"displayName":"Cedric Manouan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnI55k9QnJV4mtok5wRGE36cZcj1DZIjihnSx6=s64","userId":"00242929915047742214"}},"outputId":"4307fc3b-4ab1-4845-9771-b7b02c31d163"},"source":["!pip install cleantext"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: cleantext in /usr/local/lib/python3.7/dist-packages (1.1.3)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from cleantext) (3.2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->cleantext) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6mZFKkMDoQOu","executionInfo":{"status":"ok","timestamp":1628861342899,"user_tz":-180,"elapsed":3004,"user":{"displayName":"Cedric Manouan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnI55k9QnJV4mtok5wRGE36cZcj1DZIjihnSx6=s64","userId":"00242929915047742214"}},"outputId":"13796560-eeaa-4052-cae3-c9e3aaa38a77"},"source":["!pip install emoji"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (1.4.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RaKzU8U3otwo","executionInfo":{"status":"ok","timestamp":1628861343577,"user_tz":-180,"elapsed":691,"user":{"displayName":"Cedric Manouan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnI55k9QnJV4mtok5wRGE36cZcj1DZIjihnSx6=s64","userId":"00242929915047742214"}},"outputId":"0542b808-7ff8-445b-8952-f96b667e29eb"},"source":["!pip install transformers"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.9.2)\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xWJvW0bqnNol","executionInfo":{"status":"ok","timestamp":1628861343578,"user_tz":-180,"elapsed":14,"user":{"displayName":"Cedric Manouan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnI55k9QnJV4mtok5wRGE36cZcj1DZIjihnSx6=s64","userId":"00242929915047742214"}},"outputId":"4dea2647-1031-45cb-a724-ac827a9d3012"},"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"D4-KEg85m8ei","executionInfo":{"status":"ok","timestamp":1628861343579,"user_tz":-180,"elapsed":11,"user":{"displayName":"Cedric Manouan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnI55k9QnJV4mtok5wRGE36cZcj1DZIjihnSx6=s64","userId":"00242929915047742214"}}},"source":["import os\n","os.getcwd()\n","os.environ[\"WANDB_DISABLED\"] = \"true\""],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"l8GVP79sm8ej","executionInfo":{"status":"ok","timestamp":1628861343580,"user_tz":-180,"elapsed":11,"user":{"displayName":"Cedric Manouan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnI55k9QnJV4mtok5wRGE36cZcj1DZIjihnSx6=s64","userId":"00242929915047742214"}}},"source":["import random\n","import torch\n","import pandas as pd\n","import numpy as np\n","pd.options.display.max_colwidth = 200\n","\n","def seed_all(seed_value):\n","    random.seed(seed_value) # Python\n","    np.random.seed(seed_value) # cpu vars\n","    torch.manual_seed(seed_value) # cpu  vars\n","    \n","    if torch.cuda.is_available(): \n","        torch.cuda.manual_seed(seed_value)\n","        torch.cuda.manual_seed_all(seed_value) # gpu vars\n","        torch.backends.cudnn.deterministic = True  #needed\n","        torch.backends.cudnn.benchmark = False\n","seed_all(13)"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"3CBeaoRK82N5","executionInfo":{"status":"ok","timestamp":1628861343580,"user_tz":-180,"elapsed":10,"user":{"displayName":"Cedric Manouan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnI55k9QnJV4mtok5wRGE36cZcj1DZIjihnSx6=s64","userId":"00242929915047742214"}}},"source":["import pandas as pd\n","import emoji\n","import warnings\n","import re\n","warnings.filterwarnings('ignore')\n","from cleantext import clean\n","from transformers import (AutoModel,AutoModelForMaskedLM, \n","                          AutoTokenizer, LineByLineTextDataset,\n","                          DataCollatorForLanguageModeling,\n","                          Trainer, TrainingArguments)"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"z-gD2I7Mm8ek","executionInfo":{"status":"ok","timestamp":1628861343581,"user_tz":-180,"elapsed":10,"user":{"displayName":"Cedric Manouan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnI55k9QnJV4mtok5wRGE36cZcj1DZIjihnSx6=s64","userId":"00242929915047742214"}}},"source":["def give_emoji_free_text(text):\n","    allchars = [str for str in text.encode().decode('utf-8')]\n","    emoji_list = [c for c in allchars if c in emoji.UNICODE_EMOJI]\n","    clean_text = ' '.join([str for str in text.encode().decode('utf-8').split() if not any(i in str for i in emoji_list)])\n","    return clean_text\n","\n","def cleaning_text(text):\n","  text = text.lower()\n","  text = re.sub(r'[^\\w\\s]', ' ', text)\n","  text = re.sub(r'\\d+', '', text)\n","  text = text.replace(\"&amp\",\" \")\n","  text = \" \".join(text.split())\n","  return text\n"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"LXlH0u9E9BFp","executionInfo":{"status":"ok","timestamp":1628861346942,"user_tz":-180,"elapsed":3370,"user":{"displayName":"Cedric Manouan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnI55k9QnJV4mtok5wRGE36cZcj1DZIjihnSx6=s64","userId":"00242929915047742214"}}},"source":["train_data=pd.read_csv(\"/content/gdrive/MyDrive/Hackathon/Train.csv\")\n","train_data['tweet']=train_data['tweet'].apply(cleaning_text)\n","train_data['tweet']=train_data['tweet'].apply(give_emoji_free_text)\n","\n","\n","test_data=pd.read_csv(\"/content/gdrive/MyDrive/Hackathon/Test.csv\")\n","test_data['tweet']=test_data['tweet'].apply(cleaning_text)\n","test_data['tweet']=test_data['tweet'].apply(give_emoji_free_text)\n","\n","\n","data = pd.concat([train_data,test_data])\n","data['tweet'] = data['tweet'].apply(lambda x: x.replace('\\n',''))\n","\n","text  = '\\n'.join(data.tweet.tolist())\n","\n","with open('text.txt','w') as f:\n","    f.write(text)"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kd_CKTYJ9kQV","executionInfo":{"status":"ok","timestamp":1628861357965,"user_tz":-180,"elapsed":11040,"user":{"displayName":"Cedric Manouan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnI55k9QnJV4mtok5wRGE36cZcj1DZIjihnSx6=s64","userId":"00242929915047742214"}},"outputId":"40188426-1aaf-4468-8cdb-c52839f98012"},"source":["model_name = 'bert-base-uncased'\n","model = AutoModelForMaskedLM.from_pretrained(model_name)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","tokenizer.save_pretrained('/content/gdrive/MyDrive/Hackathon/zindi_bert_base')"],"execution_count":33,"outputs":[{"output_type":"stream","text":["loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of BertForMaskedLM were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","tokenizer config file saved in /content/gdrive/MyDrive/Hackathon/zindi_bert_base/tokenizer_config.json\n","Special tokens file saved in /content/gdrive/MyDrive/Hackathon/zindi_bert_base/special_tokens_map.json\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["('/content/gdrive/MyDrive/Hackathon/zindi_bert_base/tokenizer_config.json',\n"," '/content/gdrive/MyDrive/Hackathon/zindi_bert_base/special_tokens_map.json',\n"," '/content/gdrive/MyDrive/Hackathon/zindi_bert_base/vocab.txt',\n"," '/content/gdrive/MyDrive/Hackathon/zindi_bert_base/added_tokens.json',\n"," '/content/gdrive/MyDrive/Hackathon/zindi_bert_base/tokenizer.json')"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"qYbzlGk5m8em","executionInfo":{"status":"ok","timestamp":1628861368318,"user_tz":-180,"elapsed":10356,"user":{"displayName":"Cedric Manouan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnI55k9QnJV4mtok5wRGE36cZcj1DZIjihnSx6=s64","userId":"00242929915047742214"}}},"source":["data['length'] = data['tweet'].apply(lambda z:len(tokenizer.tokenize(z)))"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sHTIZPCSm8em","executionInfo":{"status":"ok","timestamp":1628861368319,"user_tz":-180,"elapsed":9,"user":{"displayName":"Cedric Manouan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnI55k9QnJV4mtok5wRGE36cZcj1DZIjihnSx6=s64","userId":"00242929915047742214"}},"outputId":"14dfb3c4-d170-4d30-8a65-eeb0d526ab30"},"source":["data['length'].describe([0.7,0.8,0.9,0.95,0.99])"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["count    55231.000000\n","mean        40.902229\n","std         15.954082\n","min          3.000000\n","50%         45.000000\n","70%         53.000000\n","80%         56.000000\n","90%         59.000000\n","95%         61.000000\n","99%         66.000000\n","max        128.000000\n","Name: length, dtype: float64"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":266},"id":"9SubRIgn9kMw","executionInfo":{"status":"error","timestamp":1628861377945,"user_tz":-180,"elapsed":9632,"user":{"displayName":"Cedric Manouan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnI55k9QnJV4mtok5wRGE36cZcj1DZIjihnSx6=s64","userId":"00242929915047742214"}},"outputId":"42e1b959-4289-48d4-c38b-3423754fd1d6"},"source":["train_dataset = LineByLineTextDataset(\n","    tokenizer=tokenizer,\n","    file_path=\"text.txt\", #mention train text file here\n","    block_size=80)\n","\n","valid_dataset = LineByLineTextDataset(\n","    tokenizer=tokenizer,\n","    file_path=\"text.txt\", #mention valid text file here\n","    block_size=80)\n","\n","data_collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer, mlm=True, mlm_probability=0.20)\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./zindi_bert_base_chk\", #select model path for checkpoint\n","    overwrite_output_dir=True,\n","    num_train_epochs=15,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    evaluation_strategy= 'steps',\n","    save_total_limit=2,\n","    seed = 13,\n","    metric_for_best_model='eval_loss',\n","    greater_is_better=False,\n","    load_best_model_at_end =True,\n","    prediction_loss_only=True)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=train_dataset,\n","    eval_dataset=valid_dataset)\n","trainer.train()\n","trainer.save_model(f'./zindi_bert_base')\n"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Creating features from dataset file at text.txt\n","Creating features from dataset file at text.txt\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-442fcc92abe8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mfile_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#mention valid text file here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     block_size=80)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m data_collator = DataCollatorForLanguageModeling(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"D_AfNN0vCIS4","executionInfo":{"status":"aborted","timestamp":1628861377943,"user_tz":-180,"elapsed":6,"user":{"displayName":"Cedric Manouan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnI55k9QnJV4mtok5wRGE36cZcj1DZIjihnSx6=s64","userId":"00242929915047742214"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"598TIjWKm8en","executionInfo":{"status":"aborted","timestamp":1628861377945,"user_tz":-180,"elapsed":8,"user":{"displayName":"Cedric Manouan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnI55k9QnJV4mtok5wRGE36cZcj1DZIjihnSx6=s64","userId":"00242929915047742214"}}},"source":[""],"execution_count":null,"outputs":[]}]}